{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DfejMHs4lr8V"
   },
   "source": [
    "*Copyright 2024 The Penzai Authors.*\n",
    "\n",
    "*Licensed under the Apache License, Version 2.0 (the \"License\"); you may not use this file except in compliance with the License.\n",
    "You may obtain a copy of the License at*\n",
    "\n",
    "> http://www.apache.org/licenses/LICENSE-2.0\n",
    "\n",
    "*Unless required by applicable law or agreed to in writing, software\n",
    "distributed under the License is distributed on an \"AS IS\" BASIS,\n",
    "WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or  implied.\n",
    "See the License for the specific language governing permissions and\n",
    "limitations under the License.*\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "USGIPdLYDzSo"
   },
   "source": [
    "[![Open in Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/google-deepmind/penzai/blob/main/notebooks/how_to_think_in_penzai.ipynb) [![Open in Kaggle](https://kaggle.com/static/images/open-in-kaggle.svg)](https://kaggle.com/kernels/welcome?src=https://github.com/google-deepmind/penzai/blob/main/notebooks/how_to_think_in_penzai.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2VR1iZX8oUH_"
   },
   "source": [
    "# How to Think in Penzai"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7yK4NS1yoe_X"
   },
   "source": [
    "Penzai prioritizes legibility, visualization, and easy editing of neural network models. It strives to follow a simple mental model, avoid magic wherever possible, and decompose into modular tools that can be combined without getting in your way. This means that Penzai models are often structured somewhat differently than models in other libraries like PyTorch, Flax, or Keras.\n",
    "\n",
    "This document explains the key principles behind Penzai's design, and should teach you all you need to know to start using Penzai."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "XGZH58j8mPkj"
   },
   "outputs": [],
   "source": [
    "try:\n",
    "  import penzai\n",
    "except ImportError:\n",
    "  !pip install penzai[notebook]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "PGansFBXFes2"
   },
   "outputs": [],
   "source": [
    "import collections\n",
    "import dataclasses\n",
    "import jax\n",
    "import jax.numpy as jnp\n",
    "from typing import Any, Callable, Sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "uWNMzWrBvgAX"
   },
   "outputs": [],
   "source": [
    "import penzai\n",
    "from penzai import pz\n",
    "from penzai.example_models import simple_mlp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JtySZ1ofS7l-"
   },
   "source": [
    "## Principles"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5Py-jS4vpxDT"
   },
   "source": [
    "### 1. What You See is What You Get"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cGMfKdCnK11t"
   },
   "source": [
    "The first central principle of Penzai, which influences almost every aspect of its design, is that everything is visualizable by default, and nothing is hidden from the user.\n",
    "\n",
    "Penzai includes a powerful interactive IPython pretty-printer with automatic embedded array visualizations (called Treescope), which can be used to look inside any JAX-compatible data structure. You can enable Treescope like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5P0luQouK1nU"
   },
   "outputs": [],
   "source": [
    "pz.ts.register_as_default()\n",
    "\n",
    "# Optional automatic array visualization extras:\n",
    "pz.ts.register_autovisualize_magic()\n",
    "pz.enable_interactive_context()\n",
    "pz.ts.active_autovisualizer.set_interactive(pz.ts.ArrayAutovisualizer())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wVz_WgmvEoHk"
   },
   "source": [
    "Penzai goes out of its way to make sure that the pretty-printer representation of a model tells you everything you need to know about it:\n",
    "\n",
    "- Every sublayer of the model is directly contained in its parent, and can be viewed by expanding it.\n",
    "- Every parameter is an attribute of the layer that owns it.\n",
    "- Every model is immutable, and all state is explicitly tracked as a node in the model tree.\n",
    "- Any shared parameters are tracked structurally using the data-effect system, *not* using Python references.\n",
    "\n",
    "For instance, here's what a simple MLP looks like in Penzai:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "qr7-zSPHE0Nl"
   },
   "outputs": [],
   "source": [
    "mlp = pz.nn.initialize_parameters(\n",
    "    simple_mlp.MLP.from_config([8, 32, 32, 8]),\n",
    "    jax.random.key(0),\n",
    ")\n",
    "mlp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jQ3XX08DE8Zd"
   },
   "source": [
    "Try clicking to expand or collapse different sublayers! We've turned on automatic array visualization, so if you expand one of the parameters, you can immediately visualize its shape and array data.\n",
    "\n",
    "Importantly, this isn't just a pretty visualization of the model, it's actually a **fully-roundtrippable specification of the model structure**. You can press `r` to enable roundtrip mode, and then directly copy and execute the pretty-printed output:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7GIT7BY3FPP5"
   },
   "outputs": [],
   "source": [
    "copied = penzai.example_models.simple_mlp.MLP( # Sequential\n",
    "  sublayers=[\n",
    "    penzai.nn.linear_and_affine.Affine( # Sequential\n",
    "      sublayers=[\n",
    "        penzai.nn.linear_and_affine.Linear(weights=penzai.nn.parameters.Parameter(value=penzai.core.named_axes.NamedArray(named_axes=collections.OrderedDict({'features': 8, 'features_out': 32}), data_array=penzai.treescope.copypaste_fallback.NotRoundtrippable(original_repr='<jax.Array float32(8, 32) ≈-0.0019 ±0.22 [≥-0.38, ≤0.38] nonzero:256>', original_id=23148094748192, original_type=jax.Array)), name='Affine_0.Linear.weights'), in_axis_names=('features',), out_axis_names=('features_out',)),\n",
    "        penzai.nn.linear_and_affine.RenameAxes(old=('features_out',), new=('features',)),\n",
    "        penzai.nn.linear_and_affine.AddBias(bias=penzai.nn.parameters.Parameter(value=penzai.core.named_axes.NamedArray(named_axes=collections.OrderedDict({'features': 32}), data_array=penzai.treescope.copypaste_fallback.NotRoundtrippable(original_repr='<jax.Array float32(32,) ≈0.0 ±0.0 [≥0.0, ≤0.0] zero:32>', original_id=23148094743968, original_type=jax.Array)), name='Affine_0.AddBias.bias'), new_axis_names=()),\n",
    "      ],\n",
    "    ),\n",
    "    penzai.nn.basic_ops.Elementwise(fn=jax.nn.relu),\n",
    "    penzai.nn.linear_and_affine.Affine( # Sequential\n",
    "      sublayers=[penzai.nn.linear_and_affine.Linear(weights=penzai.nn.parameters.Parameter(value=penzai.core.named_axes.NamedArray(named_axes=collections.OrderedDict({'features': 32, 'features_out': 32}), data_array=penzai.treescope.copypaste_fallback.NotRoundtrippable(original_repr='<jax.Array float32(32, 32) ≈-0.0037 ±0.18 [≥-0.31, ≤0.31] nonzero:1_024>', original_id=23147983056352, original_type=jax.Array)), name='Affine_1.Linear.weights'), in_axis_names=('features',), out_axis_names=('features_out',)), penzai.nn.linear_and_affine.RenameAxes(old=('features_out',), new=('features',)), penzai.nn.linear_and_affine.AddBias(bias=penzai.nn.parameters.Parameter(value=penzai.core.named_axes.NamedArray(named_axes=collections.OrderedDict({'features': 32}), data_array=penzai.treescope.copypaste_fallback.NotRoundtrippable(original_repr='<jax.Array float32(32,) ≈0.0 ±0.0 [≥0.0, ≤0.0] zero:32>', original_id=23148002433952, original_type=jax.Array)), name='Affine_1.AddBias.bias'), new_axis_names=())],\n",
    "    ),\n",
    "    penzai.nn.basic_ops.Elementwise(fn=jax.nn.relu),\n",
    "    penzai.nn.linear_and_affine.Affine( # Sequential\n",
    "      sublayers=[penzai.nn.linear_and_affine.Linear(weights=penzai.nn.parameters.Parameter(value=penzai.core.named_axes.NamedArray(named_axes=collections.OrderedDict({'features': 32, 'features_out': 8}), data_array=penzai.treescope.copypaste_fallback.NotRoundtrippable(original_repr='<jax.Array float32(32, 8) ≈-0.0052 ±0.23 [≥-0.38, ≤0.39] nonzero:256>', original_id=23148002427616, original_type=jax.Array)), name='Affine_2.Linear.weights'), in_axis_names=('features',), out_axis_names=('features_out',)), penzai.nn.linear_and_affine.RenameAxes(old=('features_out',), new=('features',)), penzai.nn.linear_and_affine.AddBias(bias=penzai.nn.parameters.Parameter(value=penzai.core.named_axes.NamedArray(named_axes=collections.OrderedDict({'features': 8}), data_array=penzai.treescope.copypaste_fallback.NotRoundtrippable(original_repr='Array([0., 0., 0., 0., 0., 0., 0., 0.], dtype=float32)', original_id=23147983059168, original_type=jax.Array)), name='Affine_2.AddBias.bias'), new_axis_names=())],\n",
    "    ),\n",
    "  ],\n",
    ")\n",
    "copied"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EvccY3LITshR"
   },
   "source": [
    "And this produces a perfect copy of your model (including everything except the array data):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "v-BoPeEILXsV"
   },
   "outputs": [],
   "source": [
    "jax.tree_util.tree_structure(mlp) == jax.tree_util.tree_structure(copied)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2KYTPeNcFa1Z"
   },
   "source": [
    "As a user of a Penzai model, you should never have to worry about hidden state or Python object references. If it doesn't show up in the pretty-printed output, it's not part of the model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DRA69HYesgn_"
   },
   "source": [
    "### 2. Everything is Patchable"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Er0JhNVzF3mD"
   },
   "source": [
    "The second core principle is that Penzai models are designed to be freely modified after they are built, including isolating small parts of larger models, combining models together, or inserting arbitrary logic at arbitrary points in a model's forward pass.\n",
    "\n",
    "Penzai includes a structure-rewriting utility, `pz.select`, which lets you make arbitrary modifications to Penzai models using `.at(...).set(...)`-style syntax. For instance, you can pull out parameters:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "EoWmFsAfGmmZ"
   },
   "outputs": [],
   "source": [
    "# Find the parameters:\n",
    "pz.select(mlp).at_instances_of(pz.nn.Parameter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "QFdgMdOhLovO"
   },
   "outputs": [],
   "source": [
    "# Extract them:\n",
    "pz.select(mlp).at_instances_of(pz.nn.Parameter).get_sequence()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OKzfMGgqGm2E"
   },
   "source": [
    "Or insert new logic:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "mo4gGbscGqLA"
   },
   "outputs": [],
   "source": [
    "@pz.pytree_dataclass\n",
    "class HelloWorld(pz.Layer):\n",
    "  def __call__(self, arg):\n",
    "    pz.show(\"Hello world! My value:\", arg)\n",
    "    return arg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1xMgPsdzL1Wm"
   },
   "outputs": [],
   "source": [
    "# Insert a new layer after each nonlinearity:\n",
    "patched = (\n",
    "    pz.select(mlp).at_instances_of(pz.nn.Elementwise).insert_after(HelloWorld())\n",
    ")\n",
    "pz.select(patched).at_instances_of(HelloWorld)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "53OjRmwSMIaQ"
   },
   "outputs": [],
   "source": [
    "# Run it:\n",
    "patched(pz.nx.ones({\"features\": 8}))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lR0kfnlNGqZa"
   },
   "source": [
    "You can even click the \"copy\" button next to any part of the pretty-printed output to copy a path to that node, allowing you to extract or modify it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "oXdyYoajGt5i"
   },
   "outputs": [],
   "source": [
    "# Copied by clicking above:\n",
    "path_fn = (lambda root: root.sublayers[2].sublayers[0])\n",
    "path_fn(mlp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PnqYMGJgGrut"
   },
   "source": [
    "To make all of this work, Penzai models are designed to be *as permissive as possible* about their contents after construction. For instance, the MLP class doesn't specifically require it's children to be Affine layers (a.k.a. Dense layers), and doesn't run the activation functions directly. Instead, it is a subclass of `Sequential`, and it just runs its sublayers in sequence without caring about their types. This means we are free to insert new logic into an `MLP` at runtume to customize its behavior, without having to change its original code."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "43L1P9r4p2pV"
   },
   "source": [
    "### 3. Models Are (Just) Callable, JIT-able PyTree Data Structures"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ko2QuWmJF877"
   },
   "source": [
    "Every Penzai model object is a frozen [Python dataclass](https://docs.python.org/3/library/dataclasses.html) and a [JAX Pytree](https://jax.readthedocs.io/en/latest/pytrees.html). This means that all of the instance variables of Penzai models are explicitly typed and tracked, and that any Penzai model can be traversed using `jax.tree_util`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "61FUfDhIF8mS"
   },
   "outputs": [],
   "source": [
    "jax.tree_util.tree_flatten(mlp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wK-dxCCtNFWl"
   },
   "source": [
    "Models own their parameters, so you can just call them directly:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "bLahyDi6NVBL"
   },
   "outputs": [],
   "source": [
    "mlp(pz.nx.ones({\"features\": 8}))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "k4TNUyCzNZV2"
   },
   "source": [
    "Or, just as easily, call one of their sublayers:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9wqJuLtXNfkz"
   },
   "outputs": [],
   "source": [
    "mlp.sublayers[2].sublayers[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "xzcjwkVJNMmX"
   },
   "outputs": [],
   "source": [
    "mlp.sublayers[2].sublayers[0](pz.nx.ones({\"features\": 32}))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SZO-S9gaG6eN"
   },
   "source": [
    "The PyTree leaves of a Penzai model are always the parameters and other NDArray contents. This means they can be passed through JAX transformations like `jax.jit` directly, without having to use special Penzai-specific wrappers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "E9s2vKJaG_Og"
   },
   "outputs": [],
   "source": [
    "@jax.jit\n",
    "def my_func(model, arg):\n",
    "  return model(arg)\n",
    "\n",
    "my_func(mlp, pz.nx.ones({\"features\": 8}))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VSG9J3_WG_g6"
   },
   "source": [
    "Penzai models work seamlessly with utilities designed for Python dataclasses or JAX Pytrees. In fact, the Treescope pretty-printer will pretty-print any dataclass, and the `pz.select` rewriting system can modify any JAX Pytree, without requiring special support for Penzai models in particular! Penzai's tools are designed to put you in control and let you mix-and-match components from different libraries."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eFNqI_6EHijJ"
   },
   "source": [
    "Penzai's approach of callable PyTree dataclasses is heavily inspired by [Equinox](https://docs.kidger.site/equinox/), so if you're familiar with Equinox, you should feel right at home with Penzai! The main differences from Equinox:\n",
    "- Penzai doesn't use filtered transformations; instead, parameters are explicitly annotated (discussed later), and all non-array data should be marked as such using `dataclasses.field(metadata={\"pytree_node\": False})`.\n",
    "- Penzai layers use an explicit `@pz.pytree_dataclass` decorator, which makes it obvious to readers of your code that this class uses dataclass semantics. `pz.pytree_dataclass` also lets you customize the dataclass arguments, and catches common footguns of Python dataclasses (such as the ordering of attributes in dataclass inheritance).\n",
    "- By convention, Penzai layers do not override `__init__`. Instead, construction is done using a separate class method (often called `MyLayer.from_config(...)`). This is to ensure that you can always rebuild the layer from its pretty-printed representation, even if you've patched it.\n",
    "- Conventions for idiomatic Penzai layers differ somewhat from Equinox modules, as discussed in the remaining principles below."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "a7NRAVg1sCQC"
   },
   "source": [
    "### 4. Axes Are Referenced By Name, But Used Positionally"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fw_Y1At_N5GM"
   },
   "source": [
    "Axis ordering can make it harder to reason about what complex models are doing, especially when trying to visualize or intervene on internal activations, or when using models from an unfamiliar codebase. It's often easier to refer to axes by name. But you shouldn't have to learn a whole new array API just to use named axes; the existing Numpy and JAX APIs are pretty good!\n",
    "\n",
    "Penzai strikes a middle ground using a lightweight *locally-positional* named-axis system, defined in a single file and with a minimal API surface. In short:\n",
    "\n",
    "- The `pz.nx.NamedArray` class wraps an ordinary array, and assigns each axis to either a position *or* a name (but not both).\n",
    "- You can convert positional axes to named ones using `.tag(...)`, or convert named axes back to positional axes using `.untag(...)`.\n",
    "- Any JAX function can be *lifted* using `pz.nx.nmap`. The lifted function will act normally over the positional axes but will be automatically vectorized over all of the named axes (using `jax.vmap` internally). Only `NamedArray` arguments are processed in this way; other arguments are just passed through.\n",
    "- Standard array methods and operators (e.g. `.sum()`, `+`, or slicing) are also lifted so that they operate over positional axes and vectorize over named axes.\n",
    "- By convention, Penzai layers use axis names to define their interface, but then use `.untag`, `nmap`, and `.tag` to implement their internal logic.\n",
    "\n",
    "For instance, here's how you might take a softmax over a vocabulary axis:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "CQZaFJfCdzNW"
   },
   "outputs": [],
   "source": [
    "# Start with a JAX array:\n",
    "array = jax.random.normal(jax.random.key(0), [8, 32])\n",
    "# Wrap it as a named array:\n",
    "wrapped = pz.nx.wrap(array)\n",
    "# Assign names:\n",
    "named = wrapped.tag(\"batch\", \"vocabulary\")\n",
    "# Visualize it:\n",
    "named"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_XNvqhVReJ6Q"
   },
   "outputs": [],
   "source": [
    "# Un-tag the vocabulary axis:\n",
    "untagged = named.untag(\"vocabulary\")\n",
    "# Map the ordinary JAX softmax function over the temporary positional axis:\n",
    "softmaxed = pz.nx.nmap(jax.nn.softmax)(untagged, axis=0)\n",
    "# Tag the positional axis with a name again:\n",
    "softmaxed.tag(\"vocabulary\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5X0GDqCXeq1o"
   },
   "source": [
    "And here's how you might wrap that in an idiomatic layer:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "P_Tf4AMSeqjo"
   },
   "outputs": [],
   "source": [
    "@pz.pytree_dataclass\n",
    "class Softmax(pz.Layer):\n",
    "  axis_name: str = dataclasses.field(metadata={\"pytree_node\": False})\n",
    "  def __call__(self, arg):\n",
    "    # Write the logic as if the argument is one dimensional:\n",
    "    arr = arg.untag(self.axis_name)\n",
    "    assert len(arr.positional_shape) == 1\n",
    "    result = pz.nx.nmap(jax.nn.softmax)(arr, axis=0)\n",
    "    # Then re-bind names at the end:\n",
    "    return result.tag(self.axis_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "y6HZK0bwe_wo"
   },
   "outputs": [],
   "source": [
    "layer = Softmax(\"vocabulary\")\n",
    "layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "53T3Rt2VfB3o"
   },
   "outputs": [],
   "source": [
    "layer(named)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fAZDZ0IofJRS"
   },
   "source": [
    "Because everything vectorizes over names by default, Penzai models can usually be used with arbitrary numbers of batch axes at runtime as long as you give them unique names. You can even insert new layers that manipulate specific batch axes by name (e.g. copying activations from one input to another), without interfering with any of the shapes in the rest of your model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PlkyAkf1p6LX"
   },
   "source": [
    "### 5. Parameters Are Tagged And Named"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "m4z1cYt_fcKv"
   },
   "source": [
    "In Penzai, every learnable parameter is identified by being an instance of `pz.nn.Parameter`. Since models are freely patchable at runtime, the location of a parameter may change after it is built, so every parameter must have a unique string name.\n",
    "\n",
    "This makes it easy to distinguish learnable parameters from frozen parameters or arraylike hyperparameters. For instance, you can get a parameter dictionary using `pz.select`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "JUo2kkLHhCKC"
   },
   "outputs": [],
   "source": [
    "{\n",
    "    param.name: param.value\n",
    "    for param in pz.select(mlp).at_instances_of(pz.nn.Parameter).get_sequence()\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ARUpPw_5hNMQ"
   },
   "source": [
    "Then freeze some parameters:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_KXnIU8shP--"
   },
   "outputs": [],
   "source": [
    "mlp_with_frozen_bias = (\n",
    "    pz.select(mlp)\n",
    "    .at_instances_of(pz.nn.AddBias)\n",
    "    .at_instances_of(pz.nn.Parameter)\n",
    "    .apply(lambda x: pz.nn.FrozenParameter(name=x.name, value=x.value))\n",
    ")\n",
    "mlp_with_frozen_bias"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8uVBhrs1hb7b"
   },
   "source": [
    "And get the new learnable parameters from the modified model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "LJh1AcMjheda"
   },
   "outputs": [],
   "source": [
    "{\n",
    "    param.name: param.value\n",
    "    for param in (\n",
    "        pz.select(mlp_with_frozen_bias)\n",
    "        .at_instances_of(pz.nn.Parameter)\n",
    "        .get_sequence()\n",
    "    )\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IbRh_R9Qhnbj"
   },
   "source": [
    "Or substitute values for them:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "XHeKvs3ah0ra"
   },
   "outputs": [],
   "source": [
    "(\n",
    "    pz.select(mlp_with_frozen_bias)\n",
    "    .at_instances_of(pz.nn.Parameter)\n",
    "    .apply(lambda param: pz.nn.Parameter(\n",
    "        name=param.name,\n",
    "        value=jax.tree_util.tree_map(jnp.zeros_like, param.value),\n",
    "    ))\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SmpTprZziBOW"
   },
   "source": [
    "You can use this to take gradients with respect to a model's parameters using `jax.grad`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "TbWz-9pAiOna"
   },
   "outputs": [],
   "source": [
    "model = mlp_with_frozen_bias\n",
    "\n",
    "def my_loss(diffble_params):\n",
    "  model_with_params = (\n",
    "      pz.select(model)\n",
    "      .at_instances_of(pz.nn.Parameter)\n",
    "      .apply(lambda param: pz.nn.Parameter(\n",
    "          name=param.name, value=diffble_params[param.name]\n",
    "      ))\n",
    "  )\n",
    "  result = model_with_params(\n",
    "      pz.nx.ones({\"features\": 8})\n",
    "  ).untag(\"features\").unwrap()\n",
    "  return jnp.sum(jnp.square(result))\n",
    "\n",
    "jax.grad(my_loss)({\n",
    "    param.name: param.value\n",
    "    for param in (\n",
    "        pz.select(model)\n",
    "        .at_instances_of(pz.nn.Parameter)\n",
    "        .get_sequence()\n",
    "    )\n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LlMfaf_qj58w"
   },
   "source": [
    "There's also a simple batteries-included training loop in `penzai.toolshed_basic_training` if you don't need to do anything fancy!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YEoCzrzxqPc0"
   },
   "source": [
    "### 6. Each Layer Takes One Argument And Does One Thing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Lug_y9o-j5jS"
   },
   "source": [
    "Penzai models are built by composing layers, where each layer implements the following interface:\n",
    "\n",
    "```python\n",
    "class Layer(pz.Struct, abc.ABC):\n",
    "  @abc.abstractmethod\n",
    "  def __call__(self, argument: Any, /) -> Any:\n",
    "    ...\n",
    "\n",
    "```\n",
    "\n",
    "In short:\n",
    "\n",
    "- Each layer defines a method `__call__`, which enables it to be called directly like a function, and which contains all of the layer's runtime logic.\n",
    "- `__call__` always takes exactly one argument, which must be passed positionally. (If necessary, this argument can be a tuple, dictionary, `pz.Struct`, or other JAX Pytree.)\n",
    "- Whenever possible, idiomatic Penzai models should not contain Python conditional branches in their `__call__`. You should be able to JIT-compile the `__call__` of any model, and there should generally be only a single control flow path through it.\n",
    "\n",
    "Penzai uses this convention because it makes it straightforward to compose layers with each other. For instance, there's an unambiguous way to pass the output of one layer as the input of another layer, since we know the other layer takes a single input.\n",
    "\n",
    "What about situations where we need to pass extra information to a layer to determine its runtime behavior? The idiomatic way to do this in Penzai depends on the specific type of information:\n",
    "\n",
    "- Configuration metadata, such as the input or output axis names for `pz.nn.Linear` or the activation function for `pz.nn.Elementwise`, are stored as attributes on the layer, and set when the layer is initially built.\n",
    "- Arrays and array-like side inputs, such as attention masks, token positions, or key-value caches, are typically stored as special \"effect\" attributes and handled by Penzai's data-effects system (discussed later).\n",
    "- Top-level model objects with multiple inputs can define a `pz.Struct` that contains all of the information they need, and take an instance of that struct as their positional argument.\n",
    "- What about configuration arguments used in other libraries, such as \"whether or not we should enable dropout\" or \"whether we are doing scoring or autoregressive decoding\", which change the behavior of the layer in different modes? Trick question! In Penzai, these different modes should usually be represented using *different classes*. You can then swap out model components using `pz.select` to switch between different model behaviors."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "C4JSPZXyz7Bo"
   },
   "source": [
    "The emphasis on \"doing one thing\" also extends to composite layers. In Penzai, composite layers are usually defined as direct compositions of simpler layers, by subclassing the `pz.nn.Sequential` combinator. Then, their responsibility at runtime is just to call their children in sequence, which means it's easy to insert new logic without interfering with the model's computation. We've already seen an example of this: the `MLP` model and `Affine` blocks in our `mlp` are both subclasses of `pz.nn.Sequential`.\n",
    "\n",
    "More complex combinators also tend to adhere to this pattern. For instance, the core `Attention` block in Penzai is purely a dataflow combinator, defined as\n",
    "\n",
    "```python\n",
    "@struct.pytree_dataclass\n",
    "class Attention(layer_base.Layer):\n",
    "  input_to_query: layer_base.LayerLike\n",
    "  input_to_key: layer_base.LayerLike\n",
    "  input_to_value: layer_base.LayerLike\n",
    "  query_key_to_attn: layer_base.LayerLike\n",
    "  attn_value_to_output: layer_base.LayerLike\n",
    "\n",
    "  def __call__(self, x: named_axes.NamedArray) -> named_axes.NamedArray:\n",
    "    query = self.input_to_query(x)\n",
    "    key = self.input_to_key(x)\n",
    "    value = self.input_to_value(x)\n",
    "    attn = self.query_key_to_attn((query, key))\n",
    "    output = self.attn_value_to_output((attn, value))\n",
    "    return output\n",
    "```\n",
    "\n",
    "All of the specific logic of computing positional embeddings, applying attention masks, and computing the softmax weights are left to the child layers, which makes it easy to go in and capture intermediates or intervene on their behaviors at any point, without needing to change the attention implementation. `Attention` itself just does a single thing: manage the routing of data between the different components, during training or scoring mode.\n",
    "\n",
    "If you want to do autoregressive decoding, you can swap out `Attention` blocks for `KVCachingAttention` blocks using something like\n",
    "```python\n",
    "(\n",
    "  pz.select(model)\n",
    "  .at_instances_of(pz.nn.Attention)\n",
    "  .apply(lambda attn: pz.nn.KVCachingAttention.from_uncached(attn, **kwargs))\n",
    ")\n",
    "```\n",
    "This produces a copy of your model that additionally manages and updates KV caches, while still supporting arbitrary child layer logic and without changing any of the rest of your model. (See the [\"Gemma from Scratch\" tutorial](gemma_from_scratch.ipynb) for more info on autoregressive decoding!)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "idaVcjoOqYVp"
   },
   "source": [
    "### 7. Configuration Happens During Construction (Not `__call__`)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "waiPbkQp3tK8"
   },
   "source": [
    "As discussed above, Penzai layers avoid passing configuration arguments at runtime, and avoid making assumptions about their child layers and parameters as much as possible. However, it's still important for layers and models to be able to configure themselves and initialize their parameters. In Penzai, all of this happens when the layers are initially constructed.\n",
    "\n",
    "By convention, Penzai layers configure themselves using a class method, often called `from_config(cls, ...)` (to avoid overriding `__init__`). `from_config`, in turn, takes all of the configuration arguments that are necessary to initialize the model, and uses them to set up their sublayers and parameter initializers. To separate the construction of a model from the initialization of parameters, parameters are initially configured as `pz.nn.UninitializedParameter` instances.\n",
    "\n",
    "We can see this by calling the `from_config` method of `simple_mlp.MLP`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "vtULzQEF8igb"
   },
   "outputs": [],
   "source": [
    "simple_mlp.MLP.from_config(\n",
    "    feature_sizes=[8, 32, 32, 8],\n",
    "    activation_fn=jax.nn.gelu,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yA4upAwA8mai"
   },
   "source": [
    "Notice that the arguments to `from_config` aren't actually stored on the `MLP` itself. Instead, they are simply used to configure and set up the list of sublayers. In general, the configuration arguments of complex models will often \"vanish\" in this way after the model is initially built.\n",
    "\n",
    "In fact, all of the custom logic of `MLP` and `Affine` is defined in the `from_config` methods, not `__call__`. Once initialized, you are free to remove them entirely without affecting the behavior of the model. For instance, this model is equivalent:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "kAiEAPgU9KQ4"
   },
   "outputs": [],
   "source": [
    "pz.nn.inline_groups(\n",
    "    pz.nn.Sequential([\n",
    "        simple_mlp.MLP.from_config(\n",
    "            feature_sizes=[8, 32, 32, 8],\n",
    "            activation_fn=jax.nn.gelu,\n",
    "        )\n",
    "    ]),\n",
    "    parent_filter=lambda _: True,\n",
    "    child_filter=lambda _: True,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "q7n-su7n93Ur"
   },
   "source": [
    "This pattern also applies to layers that are designed for hot-swapping. For instance, the `KVCachingAttention` block defines a classmethod `.from_uncached` that converts an `Attention` block into a `KVCachingAttention`, which takes ownership of the children of that `Attention` block and then discards the original block."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RW5jZiLHr2CK"
   },
   "source": [
    "### 8. Effects Enable Complex Data Flow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "boJ9vjPW-Yk9"
   },
   "source": [
    "Complex models often need to pass extra input context or random number generators around in addition to primary activation stream, which isn't natural to express directly using single-input layers. Additionally, models sometimes need to share parameters between individual layers, or update running state variables.\n",
    "\n",
    "To support models with this kind of dataflow without interfering with the rest of Penzai's design conventions, Penzai also includes a simple but powerful \"data effect\" system, built using `pz.select` and inspired by effect systems in functional programming. The key features of data effects:\n",
    "\n",
    "- Effects are explicitly represented as typed attributes in the model Pytree, and can be copied and manipulated just like ordinary layers. (Again, what you see is what you get, and everything is patchable!)\n",
    "- Effects are handled using explicit handlers, which use `pz.select` to replace the effect attributes with concrete temporary implementations.\n",
    "- All effects are handled at the Pytree level. The semantics of effects are determined by their handlers, and layers that don't use effects can safely ignore them. In fact, the implementation of effects is totally separate from the definition of `pz.Layer`, and you are free to define your own effects if the existing ones don't meet your needs.\n",
    "\n",
    "Here's an example of using data effects to implement randomness. We can initialize an MLP that uses dropout:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "LX2aQ85RC30P"
   },
   "outputs": [],
   "source": [
    "dropout_mlp = pz.nn.initialize_parameters(\n",
    "    simple_mlp.DropoutMLP.from_config(\n",
    "        feature_sizes=[8, 32, 32, 8],\n",
    "        drop_rate=0.1,\n",
    "    ),\n",
    "    jax.random.PRNGKey(0),\n",
    ")\n",
    "dropout_mlp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "e-hDlngCC-2Y"
   },
   "source": [
    "The `StochasticDropout` layers each contain a `RandomRequest`, which indicates that they need to receive random numbers in order to run. We can handle these requests using a handler:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "uZTpwlLTDQZE"
   },
   "outputs": [],
   "source": [
    "handled_dropout_mlp = pz.de.WithRandomKeyFromArg.handling(dropout_mlp)\n",
    "handled_dropout_mlp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ACrOWRlwDV0n"
   },
   "source": [
    "The `RandomRequests` have now been replaced with `HandledRandomRef` nodes, which explicitly refer to the ID of the new handler wrapper. We can then call the `handled_dropout_mlp` object, which will inject a random number generator into the two layers that need it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "JF5jEpffDsNv"
   },
   "outputs": [],
   "source": [
    "handled_dropout_mlp((pz.nx.ones({\"features\": 8}), jax.random.key(1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "AtAot7doDzBX"
   },
   "outputs": [],
   "source": [
    "handled_dropout_mlp((pz.nx.ones({\"features\": 8}), jax.random.key(2)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NUEOMiQ7D3Cm"
   },
   "source": [
    "The `StochasticDropout` layers each interface with the handler by calling `self.rng.next_key()`, and the `WithRandomKeyFromArg` is responsible for ensuring that the `rng` attributes are instantiated with something implementing this method.\n",
    "\n",
    "Penzai uses the data effects system to implement a variety of more complex features:\n",
    "\n",
    "- Side inputs (such as attention masks)\n",
    "- Side outputs (such as capturing intermediate activations)\n",
    "- Local state (such as key/value caching)\n",
    "- Random number generation (such as the dropout layers above)\n",
    "- Parameter sharing (using a custom `ParameterLike` subclass)\n",
    "\n",
    "The data effect system makes it possible to add these features to any model without needing to manually thread arguments through layers that don't use them. You can read more about the data effect system in the separate [data effects tutorial](data_effects.ipynb)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6Wy6X9jptLGy"
   },
   "source": [
    "## Putting It All Together: A Basic Penzai Neural Network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9QgMyqyHJrAt"
   },
   "source": [
    "To show how these principles interact, here's how we might implement a neural network from scratch in Penzai. We'll focus on re-implementing a basic MLP (like the running example above), and omit a few advanced features to keep things simple.\n",
    "\n",
    "An MLP is composed of a sequence of steps, including linear operations, biases, and elementwise activations. We can implement each of these using a separate layer so that we can manipulate them after the model is built, and define each using named axes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9iXn1WsUoQDr"
   },
   "outputs": [],
   "source": [
    "@pz.pytree_dataclass\n",
    "class SimpleLinear(pz.Layer):\n",
    "  \"\"\"A simple linear layer with a single input/output axis.\"\"\"\n",
    "\n",
    "  # Parameters are annotated as `ParameterLike` to allow swapping them out after\n",
    "  # initialization.\n",
    "  kernel: pz.nn.ParameterLike[pz.nx.NamedArray]\n",
    "\n",
    "  # Non-Pytree fields (which are not arraylike) should be annotated as such to\n",
    "  # tell JAX not to try to convert them:\n",
    "  features_axis: str = dataclasses.field(metadata={\"pytree_node\": False})\n",
    "\n",
    "  def __call__(self, x: pz.nx.NamedArray, /) -> pz.nx.NamedArray:\n",
    "    \"\"\"Multiplies the input by the learned kernel.\"\"\"\n",
    "    # pos_x has one positional axis\n",
    "    pos_x = x.untag(self.features_axis)\n",
    "    # pos_kernel has two positional axes\n",
    "    pos_kernel = self.kernel.value.untag(\"out_features\", \"in_features\")\n",
    "    # We can combine them using ordinary positional semantics:\n",
    "    pos_y = pz.nx.nmap(jnp.dot)(pos_kernel, pos_x)\n",
    "    return pos_y.tag(self.features_axis)\n",
    "\n",
    "  @classmethod\n",
    "  def from_config(\n",
    "      cls, in_features: int, out_features: int, features_axis: str = \"features\",\n",
    "  ) -> \"SimpleLinear\":\n",
    "    \"\"\"Constructs a linear layer from configuration arguments.\"\"\"\n",
    "    def _initializer(key):\n",
    "      arr = jax.nn.initializers.xavier_normal()(\n",
    "          key, (out_features, in_features)\n",
    "      )\n",
    "      return pz.nx.wrap(arr).tag(\"out_features\", \"in_features\")\n",
    "\n",
    "    return cls(\n",
    "        # Configure parameters using UninitializedParameter to avoid device\n",
    "        # computation until we need parameter values:\n",
    "        kernel=pz.nn.UninitializedParameter(\n",
    "            initializer=_initializer, name=\"kernel\"\n",
    "        ),\n",
    "        features_axis=features_axis,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Wosqb7sPLrXb"
   },
   "outputs": [],
   "source": [
    "@pz.pytree_dataclass\n",
    "class SimpleBias(pz.Layer):\n",
    "  \"\"\"A simple bias layer.\"\"\"\n",
    "  # The SimpleBias layer doesn't need to store its output axis name at all!\n",
    "  bias: pz.nn.ParameterLike[pz.nx.NamedArray]\n",
    "\n",
    "  def __call__(self, x: pz.nx.NamedArray, /) -> pz.nx.NamedArray:\n",
    "    \"\"\"Adds a bias to the input.\"\"\"\n",
    "    return x + self.bias.value  # Automatically vectorized!\n",
    "\n",
    "  @classmethod\n",
    "  def from_config(\n",
    "      cls, features: int, features_axis: str = \"features\",\n",
    "  ) -> \"SimpleBias\":\n",
    "    \"\"\"Constructs a bias layer from configuration arguments.\"\"\"\n",
    "    return cls(\n",
    "        bias=pz.nn.UninitializedParameter(\n",
    "            initializer=lambda _: pz.nx.zeros({features_axis: features}),\n",
    "            name=\"bias\"\n",
    "        )\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "CxNeQRFbMQyw"
   },
   "outputs": [],
   "source": [
    "@pz.pytree_dataclass\n",
    "class SimpleElementwise(pz.Layer):\n",
    "  \"\"\"A simple elementwise layer.\"\"\"\n",
    "  fn: Callable[[jax.Array], jax.Array] = dataclasses.field(\n",
    "      metadata={\"pytree_node\": False}\n",
    "  )\n",
    "\n",
    "  def __call__(self, x: pz.nx.NamedArray, /) -> pz.nx.NamedArray:\n",
    "    \"\"\"Runs the activation function.\"\"\"\n",
    "    return pz.nx.nmap(self.fn)(x)\n",
    "\n",
    "  # No need for `from_config`, since it would be the same as `__init__`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-YsDgUw4M2rX"
   },
   "source": [
    "We can then define a top-level MLP layer as a subclass of `Sequential`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "RYCIvpCoMdgd"
   },
   "outputs": [],
   "source": [
    "@pz.pytree_dataclass\n",
    "class SimpleMLP(pz.nn.Sequential):\n",
    "  # sublayers is inherited from Sequential, but we restate it here for clarity.\n",
    "  sublayers: list[pz.LayerLike]\n",
    "\n",
    "  # __call__ is inherited from Sequential, so no need to reimplement it! In\n",
    "  # fact, Sequential.__call__ is marked with @typing.final so you don't\n",
    "  # accidentally override it.\n",
    "\n",
    "  @classmethod\n",
    "  def from_config(\n",
    "      cls,\n",
    "      feature_sizes: Sequence[int],\n",
    "      activation: Callable[[jax.Array], jax.Array] = jax.nn.relu,\n",
    "      features_axis: str = \"features\",\n",
    "  ) -> \"SimpleMLP\":\n",
    "    \"\"\"Constructs a MLP with uninitialized parameters.\"\"\"\n",
    "    sublayers = []\n",
    "    for i in range(len(feature_sizes) - 1):\n",
    "      # We need to ensure parameter name uniqueness ourselves:\n",
    "      sublayers.append(pz.nn.add_parameter_prefix(f\"block_{i}\",\n",
    "          SimpleLinear.from_config(\n",
    "              feature_sizes[i], feature_sizes[i + 1], features_axis\n",
    "          )\n",
    "      ))\n",
    "      sublayers.append(pz.nn.add_parameter_prefix(f\"block_{i}\",\n",
    "          SimpleBias.from_config(\n",
    "              feature_sizes[i + 1], features_axis\n",
    "          )\n",
    "      ))\n",
    "      if i < len(feature_sizes) - 2:\n",
    "        sublayers.append(SimpleElementwise(activation))\n",
    "    return cls(sublayers)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tnxG5uUaP1t4"
   },
   "source": [
    "Next, we can configure it and print out what we got to make sure it matches what we expect:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "07sUUR6nP08u"
   },
   "outputs": [],
   "source": [
    "model_def = SimpleMLP.from_config(\n",
    "    feature_sizes=[8, 32, 32, 8],\n",
    "    activation=jax.nn.relu,\n",
    "    features_axis=\"features\",\n",
    ")\n",
    "model_def"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ax8VIPNwQbvy"
   },
   "source": [
    "Then we can initialize the parameters, perhaps under JIT:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "V8Ixev6RP39K"
   },
   "outputs": [],
   "source": [
    "model_at_init = jax.jit(pz.nn.initialize_parameters)(\n",
    "    model_def, jax.random.key(42)\n",
    ")\n",
    "model_at_init"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OaDtl3fKQ_ev"
   },
   "source": [
    "We can immediately call it with some example inputs to check that it works:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "C3DcYQovQhlE"
   },
   "outputs": [],
   "source": [
    "model_at_init(pz.nx.ones({\"features\": 8}))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "974BdsnwROWQ"
   },
   "source": [
    "Or set up a simple training loop:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4EXbp28gR-W0"
   },
   "outputs": [],
   "source": [
    "from penzai.toolshed import basic_training\n",
    "import optax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "fwm_FMplRGz4"
   },
   "outputs": [],
   "source": [
    "example_inputs = pz.nx.wrap(\n",
    "    jax.random.normal(jax.random.key(100), (100, 8))\n",
    ").tag(\"batch\", \"features\")\n",
    "example_targets = pz.nx.wrap(\n",
    "    jax.random.normal(jax.random.key(101), (100, 8))\n",
    ").tag(\"batch\", \"features\")\n",
    "\n",
    "def loss_fn(model, rng, state):\n",
    "  del rng, state  # More complex training loops could use these if needed\n",
    "  model_out = model(example_inputs)\n",
    "  losses = pz.nx.nmap(jnp.square)(model_out - example_targets)\n",
    "  loss = losses.untag(\"batch\", \"features\").unwrap().sum()\n",
    "  return (loss, None, {\"my_loss\": loss})\n",
    "\n",
    "train_step = jax.jit(basic_training.build_train_step_fn(loss_fn))\n",
    "train_state = basic_training.TrainState.initial_state(\n",
    "    model=model_at_init,\n",
    "    optimizer_def=optax.adam(0.01),\n",
    "    root_rng=jax.random.key(42),\n",
    ")\n",
    "\n",
    "outputs = []\n",
    "while train_state.step < 1000:\n",
    "  train_state, out = train_step(train_state)\n",
    "  if train_state.step % 20 == 0:\n",
    "    print(f\"At {train_state.step}: {out}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4_9ddvtxS4e_"
   },
   "source": [
    "## Summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "77SPJBeSTNyE"
   },
   "source": [
    "You now know everything you need to get started with Penzai!\n",
    "\n",
    "If you'd like to dive into a real-world example, you might be interested in the [\"Gemma from Scratch\"](gemma_from_scratch.ipynb) or [\"LoRA from Scratch\"](lora_from_scratch.ipynb) tutorials, or in the [\"Induction Heads\"](induction_heads.ipynb) demo. If you'd like to learn more about Penzai's advanced features, you could also read the guides for the [Treescope visualizer](treescope_prettyprinting.ipynb), the [selector system](selectors.ipynb), [data effects](data_effects.ipynb), or Penzai's utilities for [JIT-compilation and sharding](jitting_and_sharding.ipynb).\n",
    "\n",
    "Penzai strives to enable complex modifications and interventions on models either before or after training them, without getting in your way. Following the principles described here is a recommended starting point and a great way to take advantage of all of Penzai's tooling, but it's not strictly enforced! You're free to use Penzai's visualization and patching tools with non-Penzai models, or define your own callable PyTree components without conforming to the `pz.Layer` interface, if that makes more sense for your use case."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Ic9r1odtXZZt"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "name": "How to Think in Penzai",
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
