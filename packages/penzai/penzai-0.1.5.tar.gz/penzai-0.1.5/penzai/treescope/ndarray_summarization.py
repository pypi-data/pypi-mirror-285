# Copyright 2024 The Penzai Authors.
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.
"""Utilities for summarizing ndarray data."""

from __future__ import annotations

from typing import Any, Mapping, Union

import jax
import jax.numpy as jnp
import numpy as np
from penzai.core import context


def get_dtype_name(dtype) -> str:
  """Safely extracts a name for a dtype."""
  # Render scalar type objects as their literal names.
  if isinstance(dtype, type) and issubclass(dtype, np.generic):
    return dtype.__name__
  # Render any other dtype-like objects as the name of the concrete dtype they
  # convert to.
  try:
    return np.dtype(dtype).name
  except TypeError:
    return str(dtype)


def _is_subdtype(dtype, base) -> bool:
  """Safely checks for dtype subtyping."""
  try:
    return jnp.issubdtype(dtype, base)
  except TypeError:
    return False


@jax.jit
def _finite_mean_std_any(array):
  """Helper to compute mean and standard deviation only over finite elements."""
  isfinite = jnp.isfinite(array)
  inf_to_nan = jnp.where(isfinite, array, jnp.array(jnp.nan, dtype=array.dtype))
  mean = jnp.nanmean(inf_to_nan)
  std = jnp.nanstd(inf_to_nan)
  return mean, std, jnp.any(isfinite)


def summarize_ndarray(
    array: Union[np.ndarray, jax.Array], include_shape_and_dtype: bool = True
) -> str:
  """Summarizes an NDArray as a string.

  The summaries generated by this function have one of the forms:

    - floatX(shape) mean ±std [min, max] zero:? nonzero:? nan:? inf:? -inf:?
    - intX(shape) [min, max] zero:? nonzero:?
    - bool(shape) true:? false:?
    - other_dtype(shape)

  where ? represents the number of elements that have that property, and any
  property with no elements is omitted. When the array is empty, mean, std,
  min, and max are also omitted. When there are infinite elements, the mean
  and std are taken only over the finite ones, and nan is ignored for min/max.

  Args:
    array: An array to summarize.
    include_shape_and_dtype: Whether to include the shape and dtype in the
      summary. If False, just summarizes the values.

  Returns:
    A summary of the array.
  """
  output_parts = []
  if include_shape_and_dtype:
    output_parts.append(get_dtype_name(array.dtype))
    output_parts.append(repr(array.shape))

  if safe_to_summarize(array):
    if isinstance(array, np.ndarray):
      xnp = np
      is_numpy = True
    elif isinstance(array, jax.Array):
      # checked by safe_to_summarize
      assert not isinstance(array, jax.core.Tracer)
      xnp = jnp
      is_numpy = False
    else:
      raise ValueError(f"Not a known array type: {array}")

    with jax.core.ensure_compile_time_eval():

      if array.size:
        is_floating = _is_subdtype(array.dtype, jnp.floating)
        is_integer = _is_subdtype(array.dtype, jnp.integer)
        is_bool = _is_subdtype(array.dtype, jnp.bool_)

        if is_floating:
          if is_numpy:
            isfinite = np.isfinite(array)
            any_finite = np.any(isfinite)
            inf_to_nan = np.where(
                isfinite, array, np.array(np.nan, dtype=array.dtype)
            )
            mean = np.nanmean(inf_to_nan)
            std = np.nanstd(inf_to_nan)
          else:
            mean, std, any_finite = _finite_mean_std_any(array)
          if any_finite:
            output_parts.append(f" ≈{float(mean):.2} ±{float(std):.2}")
            output_parts.append(
                f" [≥{float(xnp.nanmin(array)):.2},"
                f" ≤{float(xnp.nanmax(array)):.2}]"
            )

        if is_integer:
          output_parts.append(f" [≥{xnp.min(array):_d}, ≤{xnp.max(array):_d}]")

        if is_floating or is_integer:
          ct_zero = xnp.count_nonzero(array == 0)
          if ct_zero:
            output_parts.append(f" zero:{ct_zero:_d}")

          ct_nonzero = xnp.count_nonzero(array)
          if ct_nonzero:
            output_parts.append(f" nonzero:{ct_nonzero:_d}")

        if is_floating:
          ct_nan = xnp.count_nonzero(xnp.isnan(array))
          if ct_nan:
            output_parts.append(f" nan:{ct_nan:_d}")

          ct_inf = xnp.count_nonzero(xnp.isposinf(array))
          if ct_inf:
            output_parts.append(f" inf:{ct_inf:_d}")

          ct_neginf = xnp.count_nonzero(xnp.isneginf(array))
          if ct_neginf:
            output_parts.append(f" -inf:{ct_neginf:_d}")

        if is_bool:
          ct_true = xnp.count_nonzero(array)
          if ct_true:
            output_parts.append(f" true:{ct_true:_d}")

          ct_false = xnp.count_nonzero(xnp.logical_not(array))
          if ct_false:
            output_parts.append(f" false:{ct_false:_d}")

  return "".join(output_parts)


summarization_threshold: context.ContextualValue[Mapping[str, int | None]] = (
    context.ContextualValue(
        module=__name__,
        qualname="summarization_threshold",
        initial_value={
            "tpu": 1_000_000_000,
            "gpu": 10_000_000,
            "default": 100_000,
        },
    )
)
"""Threshold for summarization of NDArrays for each backend.

This threshold determines the largest number of elements we will
summarize with summary statistics (e.g. mean, standard deviation)
when rendering in treescope. Larger values may make it slower to
display large NDArrays.

Each key should be the name of a JAX array platform, e.g. "cpu" or
"tpu". It can also be "numpy" to refer to Numpy arrays, or "default"
to refer to any other accelerator. The value is the size of the
array at which point we avoid showing summary statistics. `None`
means no limit.

This configuration argument is intended to be set at the top level
by the user, e.g. in IPython.
"""


def safe_to_summarize(array: Union[np.ndarray, jax.Array, Any]) -> bool:
  """Checks if the array is safe to summarize (not a tracer and not replicated)."""
  thresh_dict = summarization_threshold.get()
  if isinstance(array, jax.core.Tracer):
    return False
  if isinstance(array, np.ndarray):
    thresh = thresh_dict.get("numpy")
    if thresh is None:
      thresh = thresh_dict.get("cpu")
    if thresh is None:
      thresh = thresh_dict["default"]
    return thresh is None or array.size < thresh
  if isinstance(array, jax.Array):
    if array.is_deleted():
      return False
    if not (
        getattr(array, "is_fully_addressable", False)
        or getattr(array, "is_fully_replicated", False)
    ):
      return False
    [platform] = set(device.platform for device in array.devices())
    thresh = thresh_dict.get(platform)
    if thresh is None:
      thresh = thresh_dict["default"]
    return thresh is None or array.size < thresh
  return False


def _truncate_part_with_slices(
    array: jax.Array,
    mask: jax.Array,
    prefix_slices: tuple[slice, ...],
    remaining_edge_items_per_axis: tuple[int | None, ...],
) -> tuple[jax.Array, jax.Array]:
  """Helper to truncate names of an array.

  Args:
    array: An array to truncate.
    mask: Mask array, which must have the same number of dimensions as `array`,
      and whose axis sizes must be either 1 or the same as that axis of `array`
      (e.g. they are broadcast compatible).
    prefix_slices: Slices to apply to each axis of `array` and `mask`, starting
      at axis 0, which we have already computed.
    remaining_edge_items_per_axis: Number of edge items to keep for each axis,
      ignoring any axes whose slices are already computed in `prefix_slices`.

  Returns:
    Truncated array and mask, which will both be the same shape.
  """
  if not remaining_edge_items_per_axis:
    # Perform the base case slice.
    assert len(prefix_slices) == len(array.shape)
    truncated_array = array[prefix_slices]

    valid_mask_slices = tuple(
        slice(None) if mask.shape[i] == 1 else array_slice
        for i, array_slice in enumerate(prefix_slices)
    )
    truncated_mask = jnp.broadcast_to(
        jnp.array(mask[valid_mask_slices]), truncated_array.shape
    )
    return truncated_array, truncated_mask

  # Recursive step: extract one name, run the function on each side, and
  # concatenate.
  axis = len(prefix_slices)
  edge_items = remaining_edge_items_per_axis[0]
  if edge_items is None:
    # Don't need to slice.
    return _truncate_part_with_slices(
        array,
        mask,
        prefix_slices=prefix_slices + (slice(None),),
        remaining_edge_items_per_axis=remaining_edge_items_per_axis[1:],
    )
  else:
    assert array.shape[axis] > 2 * edge_items
    result_a, valid_a = _truncate_part_with_slices(
        array,
        mask,
        prefix_slices=prefix_slices + (slice(None, edge_items),),
        remaining_edge_items_per_axis=remaining_edge_items_per_axis[1:],
    )
    result_b, valid_b = _truncate_part_with_slices(
        array,
        mask,
        prefix_slices=prefix_slices + (slice(-edge_items, None),),
        remaining_edge_items_per_axis=remaining_edge_items_per_axis[1:],
    )
    padding_shape = list(result_a.shape)
    padding_shape[axis] = 1
    result = jnp.concatenate(
        [result_a, jnp.zeros(padding_shape, result_a.dtype), result_b],
        axis=axis,
    )
    valid = jnp.concatenate(
        [valid_a, jnp.zeros(padding_shape, valid_a.dtype), valid_b], axis=axis
    )
    return result, valid


def truncate_array_and_mask(
    array: jax.Array,
    mask: jax.Array,
    edge_items_per_axis: tuple[int | None, ...],
) -> tuple[jax.Array, jax.Array]:
  """Truncates an array along the given axis names.

  Args:
    array: Array to truncate.
    mask: Mask array, which must have the same number of dimensions as `array`,
      and whose axis sizes must be either 1 or the same as that axis of `array`
      (e.g. they are broadcast compatible).
    edge_items_per_axis: Number of edge items to keep for each axis, ignoring
      any axes whose slices are already computed in `prefix_slices`.

  Returns:
    A tuple containing a truncated version of the array along with a valid mask.
    Values taken from the original array have the valid mask as True, and there
    is one extra element in the middle with valid as False (standing in for the
    omitted elements). The return value is always fully replicated, because
    we cannot guarantee that it is evenly sharded across devices, and this
    function is usually used immediately before copying to the host.
  """
  sharding_kwargs = {}
  if hasattr(array, "sharding") and hasattr(
      array.sharding, "_device_assignment"
  ):
    # _truncate_part_with_slices usually returns slices that have odd
    # dimensions, which aren't divisible by most shardings. Unfortunately,
    # the XLA GSPMD partitioner sometimes still infers a sharding over one of
    # these axes, which then leads to partitioning errors in JAX whenever we
    # try to `device_get` the resulting array or call any additional operations
    # on it. To avoid this, we'd like to tell JAX to always produce an output
    # that is not sharded over any axis. Unfortunately, this is difficult
    # because JAX requires the in_shardings and out_shardings to have the same
    # devices in the same internal order, and at the time of writing JAX does
    # not provide any public API to look up the order of the devices in a
    # sharding (it allows looking up the device *set*, but not their order).
    # Whether or not this error happens seems to be somewhat nondeterministic.
    # To avoid this, we use the private property `_device_assignment` of
    # each sharding in order to figure out what device order it has, and then
    # explicitly request a fully-replicated output that is definitely safe to
    # retrieve.
    sharding_kwargs["out_shardings"] = (
        jax.sharding.GSPMDSharding.get_replicated(
            array.sharding._device_assignment  # pylint: disable=protected-access
        )
    )
  fn = jax.jit(
      _truncate_part_with_slices, static_argnums=(2, 3), **sharding_kwargs
  )
  return fn(array, mask, (), edge_items_per_axis)


def infer_balanced_truncation(
    shape: tuple[int, ...],
    maximum_size: int,
    cutoff_size_per_axis: int,
    minimum_edge_items: int,
    doubling_bonus: float = 10.0,
) -> tuple[int | None, ...]:
  """Infers a balanced truncation from a shape.

  This function computes a set of truncation sizes for each axis of the array
  such that it obeys the constraints about array and axis sizes, while also
  keeping the relative proportions of the array consistent (e.g. we keep more
  elements along axes that were originally longer). This means that the aspect
  ratio of the truncated array will still resemble the aspect ratio of the
  original array.

  To avoid very-unbalanced renderings and truncate longer axes more than short
  ones, this function truncates based on the square-root of the axis size by
  default.

  Args:
    shape: The shape of the array we are truncating.
    maximum_size: Maximum number of elements of an array to show. Arrays larger
      than this will be truncated along one or more axes.
    cutoff_size_per_axis: Maximum number of elements of each individual axis to
      show without truncation. Any axis longer than this will be truncated, with
      their visual size increasing logarithmically with the true axis size
      beyond this point.
    minimum_edge_items: How many values to keep along each axis for truncated
      arrays. We may keep more than this up to the budget of maximum_size.
    doubling_bonus: Number of elements to add to each axis each time it doubles
      beyond `cutoff_size_per_axis`. Used to make longer axes appear visually
      longer while still keeping them a reasonable size.

  Returns:
    A tuple of edge sizes. Each element corresponds to an axis in `shape`,
    and is either `None` (for no truncation) or an integer (corresponding to
    the number of elements to keep at the beginning and and at the end).
  """
  shape_arr = np.array(list(shape))
  remaining_elements_to_divide = maximum_size
  edge_items_per_axis = {}
  # Order our shape from smallest to largest, since the smallest axes will
  # require the least amount of truncation and will have the most stringent
  # constraints.
  sorted_axes = np.argsort(shape_arr)
  sorted_shape = shape_arr[sorted_axes]

  # Figure out maximum sizes based on the cutoff
  cutoff_adjusted_maximum_sizes = np.where(
      sorted_shape <= cutoff_size_per_axis,
      sorted_shape,
      cutoff_size_per_axis
      + doubling_bonus * np.log2(sorted_shape / cutoff_size_per_axis),
  )

  # Suppose we want to make a scaled version of the array with relative
  # axis sizes
  #   s0, s1, s2, ...
  # The total size is then
  #   size = (c * s0) * (c * s1) * (c * s2) * ...
  #   log(size) = ndim * log(c) + [ log s0 + log s1 + log s2 + ... ]
  # If we have a known final size we want to reach, we can solve for c as
  #   c = exp( (log size - [ log s0 + log s1 + log s2 + ... ]) / ndim )
  axis_proportions = np.sqrt(sorted_shape)
  log_axis_proportions = np.log(axis_proportions)
  for i in range(len(sorted_axes)):
    original_axis = sorted_axes[i]
    size = shape_arr[original_axis]
    # If we truncated this axis and every axis after it proportional to
    # their weights, how small of an axis size would we need for this
    # axis?
    log_c = (
        np.log(remaining_elements_to_divide) - np.sum(log_axis_proportions[i:])
    ) / (len(shape) - i)
    soft_limit_for_this_axis = np.exp(log_c + log_axis_proportions[i])
    cutoff_limit_for_this_axis = np.floor(
        np.minimum(
            soft_limit_for_this_axis,
            cutoff_adjusted_maximum_sizes[i],
        )
    )
    if size <= 2 * minimum_edge_items + 1 or size <= cutoff_limit_for_this_axis:
      # If this axis is already smaller than the minimum size it would have
      # after truncation, there's no reason to truncate it.
      # But pretend we did, so that other axes still grow monotonically if
      # their axis sizes increase.
      remaining_elements_to_divide = (
          remaining_elements_to_divide / soft_limit_for_this_axis
      )
      edge_items_per_axis[original_axis] = None
    elif cutoff_limit_for_this_axis < 2 * minimum_edge_items + 1:
      # If this axis is big enough to truncate, but our naive target size is
      # smaller than the minimum allowed truncation, we should truncate it
      # to the minimum size allowed instead.
      edge_items_per_axis[original_axis] = minimum_edge_items
      remaining_elements_to_divide = remaining_elements_to_divide / (
          2 * minimum_edge_items + 1
      )
    else:
      # Otherwise, truncate it and all remaining axes based on our target
      # truncations.
      for j in range(i, len(sorted_axes)):
        visual_size = np.floor(
            np.minimum(
                np.exp(log_c + log_axis_proportions[j]),
                cutoff_adjusted_maximum_sizes[j],
            )
        )
        edge_items_per_axis[sorted_axes[j]] = int(visual_size // 2)
      break

  return tuple(
      edge_items_per_axis[orig_axis] for orig_axis in range(len(shape))
  )


def compute_truncated_shape(
    shape: tuple[int, ...],
    edge_items: tuple[int | None, ...],
) -> tuple[int, ...]:
  """Computes the shape of a truncated array.

  This can be used to estimate the size of an array visualization after it has
  been truncated by `infer_balanced_truncation`.

  Args:
    shape: The original array shape.
    edge_items: Number of edge items to keep along each axis.

  Returns:
    The shape of the truncated array.
  """
  return tuple(
      orig if edge is None else 2 * edge + 1
      for orig, edge in zip(shape, edge_items)
  )


def faster_array_repr(array: np.ndarray | jax.Array) -> str:
  """Computes ``repr(array)``, only copying the rendered array elements.

  ``repr(array)`` on a very large jax Array can be slow, because it copies the
  entire array to host memory even when only a few elements are actually needed.
  We can avoid this by truncating the array on device before fetching it.

  Args:
    array: The array to summarize.

  Returns:
    A string representation of the array. May differ slightly from the ordinary
    ``repr``, but should contain the same elements.
  """
  if isinstance(array, np.ndarray):
    return repr(array)
  else:
    assert isinstance(array, jax.Array)

  if array.size < np.get_printoptions()["threshold"]:
    return repr(array)

  if array.aval is not None and array.aval.weak_type:
    dtype_str = f"dtype={array.dtype.name}, weak_type=True)"
  else:
    dtype_str = f"dtype={array.dtype.name})"

  edgeitems = np.get_printoptions()["edgeitems"]
  edge_items_per_axis = []
  for size in array.shape:
    if size > 2 * edgeitems + 1:
      edge_items_per_axis.append(edgeitems)
    else:
      edge_items_per_axis.append(None)
  array_edges, _ = truncate_array_and_mask(
      array,
      jnp.ones((1,) * array.ndim, dtype=jnp.bool_),
      edge_items_per_axis=tuple(edge_items_per_axis),
  )
  prefix = "Array("
  datastring = np.array2string(
      np.array(array_edges),
      prefix=prefix,
      suffix=",",
      separator=", ",
      threshold=0,
      edgeitems=edgeitems,
  )
  return f"{prefix}{datastring}, {dtype_str}"
