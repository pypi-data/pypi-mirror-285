##

```python
from transformers import AutoTokenizer, AutoModelForSeq2SeqLM
tokenizer = AutoTokenizer.from_pretrained("bigscience/T0_3B")
model = AutoModelForSeq2SeqLM.from_pretrained("bigscience/T0_3B")

```

```python
from sentence_transformers.util import cos_sim
from sentence_transformers import SentenceTransformer
model = SentenceTransformer('all-MiniLM-L6-v2')
sentences = ['That is a happy person', 'not Thatf  work generates emb son222']
#Sentences are encoded by calling model.encode()
embeddings = model.encode(sentences)

#Print the embeddings
for sentence, embedding in zip(sentences, embeddings):
    print("Sentence:", sentence)
    print("Embedding:", embedding)
    print("")

print(cos_sim(embeddings[0], embeddings[1]))
```

```python
# chatgpt 提供的训练例子

# 安装所需库
# pip install torch transformers langchain


import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn.metrics import accuracy_score
from transformers import pipeline

# 假设已有带标签的训练集
training_data = [
    {"title": "Tech Article", "content": "This is a tech-related article.", "category": "Tech"},
    {"title": "Sports News", "content": "Latest sports news.", "category": "Sports"},
    {"title": "General Article", "content": "A general article on various topics.", "category": "Other"},
    # ...
]

# 转为DataFrame
df_train = pd.DataFrame(training_data)

# 划分训练集和测试集
df_train, df_test = train_test_split(df_train, test_size=0.2, random_state=42)

# 使用transformers的pipeline进行分类
classifier = pipeline("text-classification", model="bert-base-uncased", tokenizer="bert-base-uncased")
classifier.train(df_train, max_epochs=3)

# 在测试集上进行预测
predictions = classifier.predict(df_test["content"])

# 评估分类器性能
accuracy = accuracy_score(df_test["category"], predictions)
print(f"Accuracy: {accuracy}")

# 使用训练好的模型进行新文章分类
new_article = {"title": "New Article", "content": "This is a new article on technology.", "category": None}
predicted_category = classifier.predict([new_article["content"]])[0]

print(f"Predicted Category: {predicted_category}")
```
