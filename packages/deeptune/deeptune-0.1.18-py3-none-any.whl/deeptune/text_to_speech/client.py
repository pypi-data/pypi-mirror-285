# This file was auto-generated by Fern from our API Definition.

import typing
from json.decoder import JSONDecodeError

from ..core.api_error import ApiError
from ..core.client_wrapper import AsyncClientWrapper, SyncClientWrapper
from ..core.pydantic_utilities import pydantic_v1
from ..core.request_options import RequestOptions
from .types.generate_response import GenerateResponse

# this is used as the default value for optional parameters
OMIT = typing.cast(typing.Any, ...)


class TextToSpeechClient:
    def __init__(self, *, client_wrapper: SyncClientWrapper):
        self._client_wrapper = client_wrapper

    def generate(
        self,
        *,
        prompt_audio_uri: str,
        target_language: str,
        target_text: str,
        checkpoint_uri: typing.Optional[str] = OMIT,
        cls_free_guidance: typing.Optional[float] = OMIT,
        embedding_language: typing.Optional[str] = OMIT,
        eta: typing.Optional[float] = OMIT,
        num_sampling_timesteps: typing.Optional[int] = OMIT,
        seed: typing.Optional[int] = OMIT,
        target_audio_dur_sec: typing.Optional[float] = OMIT,
        request_options: typing.Optional[RequestOptions] = None
    ) -> GenerateResponse:
        """
        API that converts text into lifelike speech with best-in-class latency & uses the most advanced AI audio model ever. Create voiceovers for your videos, audiobooks, or create AI chatbots for free.

        Parameters
        ----------
        prompt_audio_uri : str

        target_language : str

        target_text : str

        checkpoint_uri : typing.Optional[str]

        cls_free_guidance : typing.Optional[float]

        embedding_language : typing.Optional[str]

        eta : typing.Optional[float]

        num_sampling_timesteps : typing.Optional[int]

        seed : typing.Optional[int]

        target_audio_dur_sec : typing.Optional[float]

        request_options : typing.Optional[RequestOptions]
            Request-specific configuration.

        Returns
        -------
        GenerateResponse
            Successful response

        Examples
        --------
        from deeptune.client import DeeptuneApi

        client = DeeptuneApi(
            xi_api_key="YOUR_XI_API_KEY",
            token="YOUR_TOKEN",
        )
        client.text_to_speech.generate(
            prompt_audio_uri="prompt_audio_uri",
            target_language="target_language",
            target_text="target_text",
        )
        """
        _response = self._client_wrapper.httpx_client.request(
            "v1/api/text-to-speech",
            method="POST",
            json={
                "checkpoint_uri": checkpoint_uri,
                "cls_free_guidance": cls_free_guidance,
                "embedding_language": embedding_language,
                "eta": eta,
                "num_sampling_timesteps": num_sampling_timesteps,
                "prompt_audio_uri": prompt_audio_uri,
                "seed": seed,
                "target_audio_dur_sec": target_audio_dur_sec,
                "target_language": target_language,
                "target_text": target_text,
            },
            request_options=request_options,
            omit=OMIT,
        )
        try:
            if 200 <= _response.status_code < 300:
                return pydantic_v1.parse_obj_as(GenerateResponse, _response.json())  # type: ignore
            _response_json = _response.json()
        except JSONDecodeError:
            raise ApiError(status_code=_response.status_code, body=_response.text)
        raise ApiError(status_code=_response.status_code, body=_response_json)


class AsyncTextToSpeechClient:
    def __init__(self, *, client_wrapper: AsyncClientWrapper):
        self._client_wrapper = client_wrapper

    async def generate(
        self,
        *,
        prompt_audio_uri: str,
        target_language: str,
        target_text: str,
        checkpoint_uri: typing.Optional[str] = OMIT,
        cls_free_guidance: typing.Optional[float] = OMIT,
        embedding_language: typing.Optional[str] = OMIT,
        eta: typing.Optional[float] = OMIT,
        num_sampling_timesteps: typing.Optional[int] = OMIT,
        seed: typing.Optional[int] = OMIT,
        target_audio_dur_sec: typing.Optional[float] = OMIT,
        request_options: typing.Optional[RequestOptions] = None
    ) -> GenerateResponse:
        """
        API that converts text into lifelike speech with best-in-class latency & uses the most advanced AI audio model ever. Create voiceovers for your videos, audiobooks, or create AI chatbots for free.

        Parameters
        ----------
        prompt_audio_uri : str

        target_language : str

        target_text : str

        checkpoint_uri : typing.Optional[str]

        cls_free_guidance : typing.Optional[float]

        embedding_language : typing.Optional[str]

        eta : typing.Optional[float]

        num_sampling_timesteps : typing.Optional[int]

        seed : typing.Optional[int]

        target_audio_dur_sec : typing.Optional[float]

        request_options : typing.Optional[RequestOptions]
            Request-specific configuration.

        Returns
        -------
        GenerateResponse
            Successful response

        Examples
        --------
        from deeptune.client import AsyncDeeptuneApi

        client = AsyncDeeptuneApi(
            xi_api_key="YOUR_XI_API_KEY",
            token="YOUR_TOKEN",
        )
        await client.text_to_speech.generate(
            prompt_audio_uri="prompt_audio_uri",
            target_language="target_language",
            target_text="target_text",
        )
        """
        _response = await self._client_wrapper.httpx_client.request(
            "v1/api/text-to-speech",
            method="POST",
            json={
                "checkpoint_uri": checkpoint_uri,
                "cls_free_guidance": cls_free_guidance,
                "embedding_language": embedding_language,
                "eta": eta,
                "num_sampling_timesteps": num_sampling_timesteps,
                "prompt_audio_uri": prompt_audio_uri,
                "seed": seed,
                "target_audio_dur_sec": target_audio_dur_sec,
                "target_language": target_language,
                "target_text": target_text,
            },
            request_options=request_options,
            omit=OMIT,
        )
        try:
            if 200 <= _response.status_code < 300:
                return pydantic_v1.parse_obj_as(GenerateResponse, _response.json())  # type: ignore
            _response_json = _response.json()
        except JSONDecodeError:
            raise ApiError(status_code=_response.status_code, body=_response.text)
        raise ApiError(status_code=_response.status_code, body=_response_json)
