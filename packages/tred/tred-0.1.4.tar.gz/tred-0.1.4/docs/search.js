window.pdocSearch = (function(){
/** elasticlunr - http://weixsong.github.io * Copyright (C) 2017 Oliver Nightingale * Copyright (C) 2017 Wei Song * MIT Licensed */!function(){function e(e){if(null===e||"object"!=typeof e)return e;var t=e.constructor();for(var n in e)e.hasOwnProperty(n)&&(t[n]=e[n]);return t}var t=function(e){var n=new t.Index;return n.pipeline.add(t.trimmer,t.stopWordFilter,t.stemmer),e&&e.call(n,n),n};t.version="0.9.5",lunr=t,t.utils={},t.utils.warn=function(e){return function(t){e.console&&console.warn&&console.warn(t)}}(this),t.utils.toString=function(e){return void 0===e||null===e?"":e.toString()},t.EventEmitter=function(){this.events={}},t.EventEmitter.prototype.addListener=function(){var e=Array.prototype.slice.call(arguments),t=e.pop(),n=e;if("function"!=typeof t)throw new TypeError("last argument must be a function");n.forEach(function(e){this.hasHandler(e)||(this.events[e]=[]),this.events[e].push(t)},this)},t.EventEmitter.prototype.removeListener=function(e,t){if(this.hasHandler(e)){var n=this.events[e].indexOf(t);-1!==n&&(this.events[e].splice(n,1),0==this.events[e].length&&delete this.events[e])}},t.EventEmitter.prototype.emit=function(e){if(this.hasHandler(e)){var t=Array.prototype.slice.call(arguments,1);this.events[e].forEach(function(e){e.apply(void 0,t)},this)}},t.EventEmitter.prototype.hasHandler=function(e){return e in this.events},t.tokenizer=function(e){if(!arguments.length||null===e||void 0===e)return[];if(Array.isArray(e)){var n=e.filter(function(e){return null===e||void 0===e?!1:!0});n=n.map(function(e){return t.utils.toString(e).toLowerCase()});var i=[];return n.forEach(function(e){var n=e.split(t.tokenizer.seperator);i=i.concat(n)},this),i}return e.toString().trim().toLowerCase().split(t.tokenizer.seperator)},t.tokenizer.defaultSeperator=/[\s\-]+/,t.tokenizer.seperator=t.tokenizer.defaultSeperator,t.tokenizer.setSeperator=function(e){null!==e&&void 0!==e&&"object"==typeof e&&(t.tokenizer.seperator=e)},t.tokenizer.resetSeperator=function(){t.tokenizer.seperator=t.tokenizer.defaultSeperator},t.tokenizer.getSeperator=function(){return t.tokenizer.seperator},t.Pipeline=function(){this._queue=[]},t.Pipeline.registeredFunctions={},t.Pipeline.registerFunction=function(e,n){n in t.Pipeline.registeredFunctions&&t.utils.warn("Overwriting existing registered function: "+n),e.label=n,t.Pipeline.registeredFunctions[n]=e},t.Pipeline.getRegisteredFunction=function(e){return e in t.Pipeline.registeredFunctions!=!0?null:t.Pipeline.registeredFunctions[e]},t.Pipeline.warnIfFunctionNotRegistered=function(e){var n=e.label&&e.label in this.registeredFunctions;n||t.utils.warn("Function is not registered with pipeline. This may cause problems when serialising the index.\n",e)},t.Pipeline.load=function(e){var n=new t.Pipeline;return e.forEach(function(e){var i=t.Pipeline.getRegisteredFunction(e);if(!i)throw new Error("Cannot load un-registered function: "+e);n.add(i)}),n},t.Pipeline.prototype.add=function(){var e=Array.prototype.slice.call(arguments);e.forEach(function(e){t.Pipeline.warnIfFunctionNotRegistered(e),this._queue.push(e)},this)},t.Pipeline.prototype.after=function(e,n){t.Pipeline.warnIfFunctionNotRegistered(n);var i=this._queue.indexOf(e);if(-1===i)throw new Error("Cannot find existingFn");this._queue.splice(i+1,0,n)},t.Pipeline.prototype.before=function(e,n){t.Pipeline.warnIfFunctionNotRegistered(n);var i=this._queue.indexOf(e);if(-1===i)throw new Error("Cannot find existingFn");this._queue.splice(i,0,n)},t.Pipeline.prototype.remove=function(e){var t=this._queue.indexOf(e);-1!==t&&this._queue.splice(t,1)},t.Pipeline.prototype.run=function(e){for(var t=[],n=e.length,i=this._queue.length,o=0;n>o;o++){for(var r=e[o],s=0;i>s&&(r=this._queue[s](r,o,e),void 0!==r&&null!==r);s++);void 0!==r&&null!==r&&t.push(r)}return t},t.Pipeline.prototype.reset=function(){this._queue=[]},t.Pipeline.prototype.get=function(){return this._queue},t.Pipeline.prototype.toJSON=function(){return this._queue.map(function(e){return t.Pipeline.warnIfFunctionNotRegistered(e),e.label})},t.Index=function(){this._fields=[],this._ref="id",this.pipeline=new t.Pipeline,this.documentStore=new t.DocumentStore,this.index={},this.eventEmitter=new t.EventEmitter,this._idfCache={},this.on("add","remove","update",function(){this._idfCache={}}.bind(this))},t.Index.prototype.on=function(){var e=Array.prototype.slice.call(arguments);return this.eventEmitter.addListener.apply(this.eventEmitter,e)},t.Index.prototype.off=function(e,t){return this.eventEmitter.removeListener(e,t)},t.Index.load=function(e){e.version!==t.version&&t.utils.warn("version mismatch: current "+t.version+" importing "+e.version);var n=new this;n._fields=e.fields,n._ref=e.ref,n.documentStore=t.DocumentStore.load(e.documentStore),n.pipeline=t.Pipeline.load(e.pipeline),n.index={};for(var i in e.index)n.index[i]=t.InvertedIndex.load(e.index[i]);return n},t.Index.prototype.addField=function(e){return this._fields.push(e),this.index[e]=new t.InvertedIndex,this},t.Index.prototype.setRef=function(e){return this._ref=e,this},t.Index.prototype.saveDocument=function(e){return this.documentStore=new t.DocumentStore(e),this},t.Index.prototype.addDoc=function(e,n){if(e){var n=void 0===n?!0:n,i=e[this._ref];this.documentStore.addDoc(i,e),this._fields.forEach(function(n){var o=this.pipeline.run(t.tokenizer(e[n]));this.documentStore.addFieldLength(i,n,o.length);var r={};o.forEach(function(e){e in r?r[e]+=1:r[e]=1},this);for(var s in r){var u=r[s];u=Math.sqrt(u),this.index[n].addToken(s,{ref:i,tf:u})}},this),n&&this.eventEmitter.emit("add",e,this)}},t.Index.prototype.removeDocByRef=function(e){if(e&&this.documentStore.isDocStored()!==!1&&this.documentStore.hasDoc(e)){var t=this.documentStore.getDoc(e);this.removeDoc(t,!1)}},t.Index.prototype.removeDoc=function(e,n){if(e){var n=void 0===n?!0:n,i=e[this._ref];this.documentStore.hasDoc(i)&&(this.documentStore.removeDoc(i),this._fields.forEach(function(n){var o=this.pipeline.run(t.tokenizer(e[n]));o.forEach(function(e){this.index[n].removeToken(e,i)},this)},this),n&&this.eventEmitter.emit("remove",e,this))}},t.Index.prototype.updateDoc=function(e,t){var t=void 0===t?!0:t;this.removeDocByRef(e[this._ref],!1),this.addDoc(e,!1),t&&this.eventEmitter.emit("update",e,this)},t.Index.prototype.idf=function(e,t){var n="@"+t+"/"+e;if(Object.prototype.hasOwnProperty.call(this._idfCache,n))return this._idfCache[n];var i=this.index[t].getDocFreq(e),o=1+Math.log(this.documentStore.length/(i+1));return this._idfCache[n]=o,o},t.Index.prototype.getFields=function(){return this._fields.slice()},t.Index.prototype.search=function(e,n){if(!e)return[];e="string"==typeof e?{any:e}:JSON.parse(JSON.stringify(e));var i=null;null!=n&&(i=JSON.stringify(n));for(var o=new t.Configuration(i,this.getFields()).get(),r={},s=Object.keys(e),u=0;u<s.length;u++){var a=s[u];r[a]=this.pipeline.run(t.tokenizer(e[a]))}var l={};for(var c in o){var d=r[c]||r.any;if(d){var f=this.fieldSearch(d,c,o),h=o[c].boost;for(var p in f)f[p]=f[p]*h;for(var p in f)p in l?l[p]+=f[p]:l[p]=f[p]}}var v,g=[];for(var p in l)v={ref:p,score:l[p]},this.documentStore.hasDoc(p)&&(v.doc=this.documentStore.getDoc(p)),g.push(v);return g.sort(function(e,t){return t.score-e.score}),g},t.Index.prototype.fieldSearch=function(e,t,n){var i=n[t].bool,o=n[t].expand,r=n[t].boost,s=null,u={};return 0!==r?(e.forEach(function(e){var n=[e];1==o&&(n=this.index[t].expandToken(e));var r={};n.forEach(function(n){var o=this.index[t].getDocs(n),a=this.idf(n,t);if(s&&"AND"==i){var l={};for(var c in s)c in o&&(l[c]=o[c]);o=l}n==e&&this.fieldSearchStats(u,n,o);for(var c in o){var d=this.index[t].getTermFrequency(n,c),f=this.documentStore.getFieldLength(c,t),h=1;0!=f&&(h=1/Math.sqrt(f));var p=1;n!=e&&(p=.15*(1-(n.length-e.length)/n.length));var v=d*a*h*p;c in r?r[c]+=v:r[c]=v}},this),s=this.mergeScores(s,r,i)},this),s=this.coordNorm(s,u,e.length)):void 0},t.Index.prototype.mergeScores=function(e,t,n){if(!e)return t;if("AND"==n){var i={};for(var o in t)o in e&&(i[o]=e[o]+t[o]);return i}for(var o in t)o in e?e[o]+=t[o]:e[o]=t[o];return e},t.Index.prototype.fieldSearchStats=function(e,t,n){for(var i in n)i in e?e[i].push(t):e[i]=[t]},t.Index.prototype.coordNorm=function(e,t,n){for(var i in e)if(i in t){var o=t[i].length;e[i]=e[i]*o/n}return e},t.Index.prototype.toJSON=function(){var e={};return this._fields.forEach(function(t){e[t]=this.index[t].toJSON()},this),{version:t.version,fields:this._fields,ref:this._ref,documentStore:this.documentStore.toJSON(),index:e,pipeline:this.pipeline.toJSON()}},t.Index.prototype.use=function(e){var t=Array.prototype.slice.call(arguments,1);t.unshift(this),e.apply(this,t)},t.DocumentStore=function(e){this._save=null===e||void 0===e?!0:e,this.docs={},this.docInfo={},this.length=0},t.DocumentStore.load=function(e){var t=new this;return t.length=e.length,t.docs=e.docs,t.docInfo=e.docInfo,t._save=e.save,t},t.DocumentStore.prototype.isDocStored=function(){return this._save},t.DocumentStore.prototype.addDoc=function(t,n){this.hasDoc(t)||this.length++,this.docs[t]=this._save===!0?e(n):null},t.DocumentStore.prototype.getDoc=function(e){return this.hasDoc(e)===!1?null:this.docs[e]},t.DocumentStore.prototype.hasDoc=function(e){return e in this.docs},t.DocumentStore.prototype.removeDoc=function(e){this.hasDoc(e)&&(delete this.docs[e],delete this.docInfo[e],this.length--)},t.DocumentStore.prototype.addFieldLength=function(e,t,n){null!==e&&void 0!==e&&0!=this.hasDoc(e)&&(this.docInfo[e]||(this.docInfo[e]={}),this.docInfo[e][t]=n)},t.DocumentStore.prototype.updateFieldLength=function(e,t,n){null!==e&&void 0!==e&&0!=this.hasDoc(e)&&this.addFieldLength(e,t,n)},t.DocumentStore.prototype.getFieldLength=function(e,t){return null===e||void 0===e?0:e in this.docs&&t in this.docInfo[e]?this.docInfo[e][t]:0},t.DocumentStore.prototype.toJSON=function(){return{docs:this.docs,docInfo:this.docInfo,length:this.length,save:this._save}},t.stemmer=function(){var e={ational:"ate",tional:"tion",enci:"ence",anci:"ance",izer:"ize",bli:"ble",alli:"al",entli:"ent",eli:"e",ousli:"ous",ization:"ize",ation:"ate",ator:"ate",alism:"al",iveness:"ive",fulness:"ful",ousness:"ous",aliti:"al",iviti:"ive",biliti:"ble",logi:"log"},t={icate:"ic",ative:"",alize:"al",iciti:"ic",ical:"ic",ful:"",ness:""},n="[^aeiou]",i="[aeiouy]",o=n+"[^aeiouy]*",r=i+"[aeiou]*",s="^("+o+")?"+r+o,u="^("+o+")?"+r+o+"("+r+")?$",a="^("+o+")?"+r+o+r+o,l="^("+o+")?"+i,c=new RegExp(s),d=new RegExp(a),f=new RegExp(u),h=new RegExp(l),p=/^(.+?)(ss|i)es$/,v=/^(.+?)([^s])s$/,g=/^(.+?)eed$/,m=/^(.+?)(ed|ing)$/,y=/.$/,S=/(at|bl|iz)$/,x=new RegExp("([^aeiouylsz])\\1$"),w=new RegExp("^"+o+i+"[^aeiouwxy]$"),I=/^(.+?[^aeiou])y$/,b=/^(.+?)(ational|tional|enci|anci|izer|bli|alli|entli|eli|ousli|ization|ation|ator|alism|iveness|fulness|ousness|aliti|iviti|biliti|logi)$/,E=/^(.+?)(icate|ative|alize|iciti|ical|ful|ness)$/,D=/^(.+?)(al|ance|ence|er|ic|able|ible|ant|ement|ment|ent|ou|ism|ate|iti|ous|ive|ize)$/,F=/^(.+?)(s|t)(ion)$/,_=/^(.+?)e$/,P=/ll$/,k=new RegExp("^"+o+i+"[^aeiouwxy]$"),z=function(n){var i,o,r,s,u,a,l;if(n.length<3)return n;if(r=n.substr(0,1),"y"==r&&(n=r.toUpperCase()+n.substr(1)),s=p,u=v,s.test(n)?n=n.replace(s,"$1$2"):u.test(n)&&(n=n.replace(u,"$1$2")),s=g,u=m,s.test(n)){var z=s.exec(n);s=c,s.test(z[1])&&(s=y,n=n.replace(s,""))}else if(u.test(n)){var z=u.exec(n);i=z[1],u=h,u.test(i)&&(n=i,u=S,a=x,l=w,u.test(n)?n+="e":a.test(n)?(s=y,n=n.replace(s,"")):l.test(n)&&(n+="e"))}if(s=I,s.test(n)){var z=s.exec(n);i=z[1],n=i+"i"}if(s=b,s.test(n)){var z=s.exec(n);i=z[1],o=z[2],s=c,s.test(i)&&(n=i+e[o])}if(s=E,s.test(n)){var z=s.exec(n);i=z[1],o=z[2],s=c,s.test(i)&&(n=i+t[o])}if(s=D,u=F,s.test(n)){var z=s.exec(n);i=z[1],s=d,s.test(i)&&(n=i)}else if(u.test(n)){var z=u.exec(n);i=z[1]+z[2],u=d,u.test(i)&&(n=i)}if(s=_,s.test(n)){var z=s.exec(n);i=z[1],s=d,u=f,a=k,(s.test(i)||u.test(i)&&!a.test(i))&&(n=i)}return s=P,u=d,s.test(n)&&u.test(n)&&(s=y,n=n.replace(s,"")),"y"==r&&(n=r.toLowerCase()+n.substr(1)),n};return z}(),t.Pipeline.registerFunction(t.stemmer,"stemmer"),t.stopWordFilter=function(e){return e&&t.stopWordFilter.stopWords[e]!==!0?e:void 0},t.clearStopWords=function(){t.stopWordFilter.stopWords={}},t.addStopWords=function(e){null!=e&&Array.isArray(e)!==!1&&e.forEach(function(e){t.stopWordFilter.stopWords[e]=!0},this)},t.resetStopWords=function(){t.stopWordFilter.stopWords=t.defaultStopWords},t.defaultStopWords={"":!0,a:!0,able:!0,about:!0,across:!0,after:!0,all:!0,almost:!0,also:!0,am:!0,among:!0,an:!0,and:!0,any:!0,are:!0,as:!0,at:!0,be:!0,because:!0,been:!0,but:!0,by:!0,can:!0,cannot:!0,could:!0,dear:!0,did:!0,"do":!0,does:!0,either:!0,"else":!0,ever:!0,every:!0,"for":!0,from:!0,get:!0,got:!0,had:!0,has:!0,have:!0,he:!0,her:!0,hers:!0,him:!0,his:!0,how:!0,however:!0,i:!0,"if":!0,"in":!0,into:!0,is:!0,it:!0,its:!0,just:!0,least:!0,let:!0,like:!0,likely:!0,may:!0,me:!0,might:!0,most:!0,must:!0,my:!0,neither:!0,no:!0,nor:!0,not:!0,of:!0,off:!0,often:!0,on:!0,only:!0,or:!0,other:!0,our:!0,own:!0,rather:!0,said:!0,say:!0,says:!0,she:!0,should:!0,since:!0,so:!0,some:!0,than:!0,that:!0,the:!0,their:!0,them:!0,then:!0,there:!0,these:!0,they:!0,"this":!0,tis:!0,to:!0,too:!0,twas:!0,us:!0,wants:!0,was:!0,we:!0,were:!0,what:!0,when:!0,where:!0,which:!0,"while":!0,who:!0,whom:!0,why:!0,will:!0,"with":!0,would:!0,yet:!0,you:!0,your:!0},t.stopWordFilter.stopWords=t.defaultStopWords,t.Pipeline.registerFunction(t.stopWordFilter,"stopWordFilter"),t.trimmer=function(e){if(null===e||void 0===e)throw new Error("token should not be undefined");return e.replace(/^\W+/,"").replace(/\W+$/,"")},t.Pipeline.registerFunction(t.trimmer,"trimmer"),t.InvertedIndex=function(){this.root={docs:{},df:0}},t.InvertedIndex.load=function(e){var t=new this;return t.root=e.root,t},t.InvertedIndex.prototype.addToken=function(e,t,n){for(var n=n||this.root,i=0;i<=e.length-1;){var o=e[i];o in n||(n[o]={docs:{},df:0}),i+=1,n=n[o]}var r=t.ref;n.docs[r]?n.docs[r]={tf:t.tf}:(n.docs[r]={tf:t.tf},n.df+=1)},t.InvertedIndex.prototype.hasToken=function(e){if(!e)return!1;for(var t=this.root,n=0;n<e.length;n++){if(!t[e[n]])return!1;t=t[e[n]]}return!0},t.InvertedIndex.prototype.getNode=function(e){if(!e)return null;for(var t=this.root,n=0;n<e.length;n++){if(!t[e[n]])return null;t=t[e[n]]}return t},t.InvertedIndex.prototype.getDocs=function(e){var t=this.getNode(e);return null==t?{}:t.docs},t.InvertedIndex.prototype.getTermFrequency=function(e,t){var n=this.getNode(e);return null==n?0:t in n.docs?n.docs[t].tf:0},t.InvertedIndex.prototype.getDocFreq=function(e){var t=this.getNode(e);return null==t?0:t.df},t.InvertedIndex.prototype.removeToken=function(e,t){if(e){var n=this.getNode(e);null!=n&&t in n.docs&&(delete n.docs[t],n.df-=1)}},t.InvertedIndex.prototype.expandToken=function(e,t,n){if(null==e||""==e)return[];var t=t||[];if(void 0==n&&(n=this.getNode(e),null==n))return t;n.df>0&&t.push(e);for(var i in n)"docs"!==i&&"df"!==i&&this.expandToken(e+i,t,n[i]);return t},t.InvertedIndex.prototype.toJSON=function(){return{root:this.root}},t.Configuration=function(e,n){var e=e||"";if(void 0==n||null==n)throw new Error("fields should not be null");this.config={};var i;try{i=JSON.parse(e),this.buildUserConfig(i,n)}catch(o){t.utils.warn("user configuration parse failed, will use default configuration"),this.buildDefaultConfig(n)}},t.Configuration.prototype.buildDefaultConfig=function(e){this.reset(),e.forEach(function(e){this.config[e]={boost:1,bool:"OR",expand:!1}},this)},t.Configuration.prototype.buildUserConfig=function(e,n){var i="OR",o=!1;if(this.reset(),"bool"in e&&(i=e.bool||i),"expand"in e&&(o=e.expand||o),"fields"in e)for(var r in e.fields)if(n.indexOf(r)>-1){var s=e.fields[r],u=o;void 0!=s.expand&&(u=s.expand),this.config[r]={boost:s.boost||0===s.boost?s.boost:1,bool:s.bool||i,expand:u}}else t.utils.warn("field name in user configuration not found in index instance fields");else this.addAllFields2UserConfig(i,o,n)},t.Configuration.prototype.addAllFields2UserConfig=function(e,t,n){n.forEach(function(n){this.config[n]={boost:1,bool:e,expand:t}},this)},t.Configuration.prototype.get=function(){return this.config},t.Configuration.prototype.reset=function(){this.config={}},lunr.SortedSet=function(){this.length=0,this.elements=[]},lunr.SortedSet.load=function(e){var t=new this;return t.elements=e,t.length=e.length,t},lunr.SortedSet.prototype.add=function(){var e,t;for(e=0;e<arguments.length;e++)t=arguments[e],~this.indexOf(t)||this.elements.splice(this.locationFor(t),0,t);this.length=this.elements.length},lunr.SortedSet.prototype.toArray=function(){return this.elements.slice()},lunr.SortedSet.prototype.map=function(e,t){return this.elements.map(e,t)},lunr.SortedSet.prototype.forEach=function(e,t){return this.elements.forEach(e,t)},lunr.SortedSet.prototype.indexOf=function(e){for(var t=0,n=this.elements.length,i=n-t,o=t+Math.floor(i/2),r=this.elements[o];i>1;){if(r===e)return o;e>r&&(t=o),r>e&&(n=o),i=n-t,o=t+Math.floor(i/2),r=this.elements[o]}return r===e?o:-1},lunr.SortedSet.prototype.locationFor=function(e){for(var t=0,n=this.elements.length,i=n-t,o=t+Math.floor(i/2),r=this.elements[o];i>1;)e>r&&(t=o),r>e&&(n=o),i=n-t,o=t+Math.floor(i/2),r=this.elements[o];return r>e?o:e>r?o+1:void 0},lunr.SortedSet.prototype.intersect=function(e){for(var t=new lunr.SortedSet,n=0,i=0,o=this.length,r=e.length,s=this.elements,u=e.elements;;){if(n>o-1||i>r-1)break;s[n]!==u[i]?s[n]<u[i]?n++:s[n]>u[i]&&i++:(t.add(s[n]),n++,i++)}return t},lunr.SortedSet.prototype.clone=function(){var e=new lunr.SortedSet;return e.elements=this.toArray(),e.length=e.elements.length,e},lunr.SortedSet.prototype.union=function(e){var t,n,i;this.length>=e.length?(t=this,n=e):(t=e,n=this),i=t.clone();for(var o=0,r=n.toArray();o<r.length;o++)i.add(r[o]);return i},lunr.SortedSet.prototype.toJSON=function(){return this.toArray()},function(e,t){"function"==typeof define&&define.amd?define(t):"object"==typeof exports?module.exports=t():e.elasticlunr=t()}(this,function(){return t})}();
    /** pdoc search index */const docs = [{"fullname": "tred", "modulename": "tred", "kind": "module", "doc": "<p>The <code>tred</code> module implements tensor decomposition methods such as tensor PCA \nand tensor SVD. Most of the functionality in this module can be regarded as \ndimensionality reduction strategies for order-3 datasets of shape n, p, t, \nwhere p &gt;&gt; n &gt; t.</p>\n"}, {"fullname": "tred.tsvdm", "modulename": "tred", "qualname": "tsvdm", "kind": "function", "doc": "<p>Return the t-SVDM decomposition from Kilmer et al. (2021).</p>\n\n<p>This is a modified version, inspired by the implementation at\n<a href=\"https://github.com/UriaMorP/mprod_package\">https://github.com/UriaMorP/mprod_package</a></p>\n\n<p><em>NOTE: For now, unlike some other implementations (Numpy, Scipy), we\nwill return the tensor $V$ NOT $V^T$.</em></p>\n\n<h6 id=\"parameters\">Parameters</h6>\n\n<ul>\n<li><strong>A</strong> (ndarray of shape (n, p, t)):\nData tensor</li>\n<li><strong>M</strong> (Callable[[ndarray], ndarray] or None, default=None):\nA function which expects an order-3 tensor as input, and returns the\nimage under a m-transform. If unspecified TPCA will use the Discrete\nCosine Transform (ii) from <code>scipy.fft</code>.</li>\n<li><strong>MInv</strong> (Callable[[ndarray], ndarray] or None, default=None):\nA function implementing the inverse transform of <code>M</code>.</li>\n<li><strong>keep_hats</strong> (bool, default=False):\nSetting to <code>True</code> will return the tSVDM factors in the m-transform\nspace, under the specified <code>M</code></li>\n<li><p><strong>full_frontal_slices</strong> (bool, default=True):\nTo reconstruct <code>A</code>, one only needs the first $k$ columns of\n$U$ and $V$.</p>\n\n<p>Setting this to False will return the truncated tensors.\nSee: <a href=\"https://numpy.org/doc/stable/reference/generated/numpy.linalg.svd.html\">https://numpy.org/doc/stable/reference/generated/numpy.linalg.svd.html</a></p></li>\n<li><strong>svals_matrix_form</strong> (bool, default=False):\nSetting to <code>True</code> will return a compressed version of $S$, where the\nsingular values of each f-diagonal frontal slice becomes the column of\na matrix, with <code>t</code> columns total.</li>\n</ul>\n\n<h6 id=\"returns\">Returns</h6>\n\n<ul>\n<li><strong>U_tens</strong> (ndarray of shape (n, n, t)):\nIf <code>full_frontal_slices==False</code> shape is (n, k, t) instead</li>\n<li><strong>S_tens</strong> (ndarray of shape (n, p, t)):\nIf <code>full_frontal_slices==False</code> shape is (k, k, t) instead\nIf <code>svals_matrix_form==True</code>, <code>S_mat</code> of shape (k, t) returned instead</li>\n<li><strong>V_tens</strong> (ndarray of shape (p, p, t)):\nIf <code>full_frontal_slices==False</code> shape is (p, k, t) instead</li>\n</ul>\n\n<h6 id=\"references\">References</h6>\n\n<p>Kilmer, M.E., Horesh, L., Avron, H. and Newman, E., 2021. Tensor-tensor\nalgebra for optimal representation and compression of multiway data.\nProceedings of the National Academy of Sciences, 118(28), p.e2015851118.</p>\n", "signature": "<span class=\"signature pdoc-code multiline\">(<span class=\"param\">\t<span class=\"n\">A</span>,</span><span class=\"param\">\t<span class=\"n\">M</span><span class=\"o\">=</span><span class=\"kc\">None</span>,</span><span class=\"param\">\t<span class=\"n\">Minv</span><span class=\"o\">=</span><span class=\"kc\">None</span>,</span><span class=\"param\">\t<span class=\"o\">*</span>,</span><span class=\"param\">\t<span class=\"n\">keep_hats</span><span class=\"o\">=</span><span class=\"kc\">False</span>,</span><span class=\"param\">\t<span class=\"n\">full_frontal_slices</span><span class=\"o\">=</span><span class=\"kc\">True</span>,</span><span class=\"param\">\t<span class=\"n\">svals_matrix_form</span><span class=\"o\">=</span><span class=\"kc\">False</span></span><span class=\"return-annotation\">):</span></span>", "funcdef": "def"}, {"fullname": "tred.TPCA", "modulename": "tred", "qualname": "TPCA", "kind": "class", "doc": "<p>Tensor analogue of PCA, introduced by Mor et al. (2022).</p>\n\n<p>t-SVDM tensor analogue of PCA using explicit rank truncation with explicit\nrank truncation from Mor et al. (2022), and underlying m-product framework\nfrom Kilmer et al. (2021). Takes in an $n \\times p \\times t$ input\ntensor, and transforms into a $n \\times$ <code>n_components</code> matrix of 2D\ntransformed projections.</p>\n\n<p>The input tensor is centred into Mean Deviation Form (by location), but\nnot normalized (by scale).</p>\n\n<h6 id=\"parameters\">Parameters</h6>\n\n<ul>\n<li><p><strong>n_components</strong> (int, float, or None, default=None):\nControl number of components to keep. If n_components is not set at\nall, or set to <code>None</code>, <code>n_components == min(n, p) * t</code></p>\n\n<p>If <code>n_components</code> is an integer, the TPCA will return the number of\nloadings, provided that for the tensor data passed into <code>fit</code>,\nsatisfies <code>1 &lt;= n_components &lt;= min(n, p) * t</code></p>\n\n<p>If <code>0 &lt; n_components &lt; 1</code>, TPCA will select the number of\ncompononents such that the amount of variance that needs to be\nexplained is greater than the percentage specified.</p></li>\n<li><strong>copy</strong> (bool, default=True):\nIf False, data passed to fit are overwritten and running\n<code>fit(X).transform(X)</code> will not yield the expected results. Use\n<code>fit_transform(X)</code> instead.</li>\n<li><strong>M</strong> (Callable[[ndarray], ndarray] or None, default=None):\nA function which expects an order-3 tensor as input, and returns the\nimage under a m-transform. If unspecified TPCA will use the Discrete\nCosine Transform (ii) from <code>scipy.fft</code>.</li>\n<li><strong>Minv</strong> (Callable[[ndarray], ndarray] or None, default=None):\nA function implementing the inverse transform of <code>M</code>.</li>\n<li><strong>centre</strong> (bool, default=True):\nIf False, the data tensor will not be centralized into Mean Deviation\nForm. By default, the mean horizontal slice of the tensor is\nsubtracted, so that all of the horizontal slices sum to 0, analagous\nto centering the data in PCA.</li>\n</ul>\n\n<h6 id=\"attributes\">Attributes</h6>\n\n<ul>\n<li><strong>n_, p_, t_, k_</strong> (int):\nThe dimensions of the training data. <code>k_ == min(n_, p_)</code></li>\n<li><strong>M_, MInv_</strong> (Callable[[ndarray], ndarray]):\nThe m-transform pair (forward and inverse) used for the underlying\ntensor-tensor m-product.</li>\n<li><strong>n_components_</strong> (int):\nThe estimated number of components. If <code>n_components</code> was explicitly\nset by an integer value, this will be the same as that. If\n<code>n_components</code> was a number between 0 and 1, this number is estimated\nfrom input data. Otherwise, if not set (defaults to None), it will\ndefault to $k \\times t$ in the training data.</li>\n<li><p><strong>explained_variance_ratio_</strong> (ndarray of shape (n_components_,)):\nPercentage of total variance explained by each of the selected\ncomponents. The selected components are selected so that this is\nreturned in descending order.</p>\n\n<p>If <code>n_components</code> is not set then all components are stored and\nthe sum of this ratios array is equal to 1.0.</p></li>\n<li><strong>singular_values_</strong> (ndarray of shape (n_components,)):\nThe singular values corresponding to each of the selected components.</li>\n<li><strong>mean_</strong> (ndarray of shape (p_, t_)):\nPer-feature, per-timepoint empirical mean, estimated from the\ntraining set. This is used to normalize any new data passed to\n<code>transform(X)</code>, unless centre is explicitly turned off via\n<code>centre==False</code> during object instantiation.</li>\n<li><strong>rho_</strong> (ndarray of shape (t,)):\nThe rho used in multi-rank truncation to achieve the desired explicit\nrank of <code>n_components</code>. See Mor et al. (2022) for detail.</li>\n<li><strong>loadings_matrix_</strong> (ndarray of shape (n_components_, p_)):\nThe i-th row corresponds to the column of $\\hat{V}$ which contains\nthe feature weights applied to the data (in the hat-space) to get the\ni-th TPCA component.</li>\n</ul>\n\n<h6 id=\"references\">References</h6>\n\n<p>Mor, U., Cohen, Y., Vald\u00e9s-Mas, R., Kviatcovsky, D., Elinav, E. and Avron,\nH., 2022. Dimensionality reduction of longitudinal\u2019omics data using modern\ntensor factorizations. PLoS Computational Biology, 18(7), p.e1010212.</p>\n", "bases": "sklearn.base.ClassNamePrefixFeaturesOutMixin, sklearn.base.TransformerMixin, sklearn.base.BaseEstimator"}, {"fullname": "tred.TPCA.fit", "modulename": "tred", "qualname": "TPCA.fit", "kind": "function", "doc": "<p>Fit the model with X.</p>\n\n<h6 id=\"parameters\">Parameters</h6>\n\n<ul>\n<li><strong>X</strong> (ndarray of shape (n, p, t)):\nTraining data, where <code>n</code> is the number of samples, <code>p</code> is the\nnumber of features, as <code>t</code> is the number of time points.</li>\n<li><strong>y</strong> (Ignored):\nIgnored.</li>\n</ul>\n\n<h6 id=\"returns\">Returns</h6>\n\n<ul>\n<li><strong>self</strong> (object):\nReturns the instance itself, after being fitted.</li>\n</ul>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"param\"><span class=\"bp\">self</span>, </span><span class=\"param\"><span class=\"n\">X</span>, </span><span class=\"param\"><span class=\"n\">y</span><span class=\"o\">=</span><span class=\"kc\">None</span></span><span class=\"return-annotation\">):</span></span>", "funcdef": "def"}, {"fullname": "tred.TPCA.transform", "modulename": "tred", "qualname": "TPCA.transform", "kind": "function", "doc": "<p>Apply dimensionality reduction to X.</p>\n\n<p>See the TCAM algorithm from Mor et al. (2022)</p>\n\n<h6 id=\"parameters\">Parameters</h6>\n\n<ul>\n<li><strong>X</strong> (ndarray of shape (n, p, t)):\nTraining data, where <code>n</code> is the number of samples, <code>p</code> is the\nnumber of features, as <code>t</code> is the number of time points.</li>\n<li><strong>y</strong> (Ignored):\nIgnored.</li>\n</ul>\n\n<h6 id=\"returns\">Returns</h6>\n\n<ul>\n<li><strong>X_transformed</strong> (ndarray of shape (n, n_components)):\nTCAM projections in 2D transformed space.</li>\n</ul>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"param\"><span class=\"bp\">self</span>, </span><span class=\"param\"><span class=\"n\">X</span></span><span class=\"return-annotation\">):</span></span>", "funcdef": "def"}, {"fullname": "tred.TPCA.fit_transform", "modulename": "tred", "qualname": "TPCA.fit_transform", "kind": "function", "doc": "<p>Fit the model with X and apply the dimensionality reduction on X.</p>\n\n<p>The output here will not be identical to calling fix(X).transform(X).\nBut, the two give the same results up to machine precision. We\nprovide a brief discussion of this below.</p>\n\n<h6 id=\"parameters\">Parameters</h6>\n\n<ul>\n<li><strong>X</strong> (ndarray of shape (n, p, t)):\nTraining data, where <code>n</code> is the number of samples, <code>p</code> is the\nnumber of features, as <code>t</code> is the number of time points.</li>\n<li><strong>y</strong> (Ignored):\nIgnored.</li>\n</ul>\n\n<h6 id=\"returns\">Returns</h6>\n\n<ul>\n<li><strong>X_transformed</strong> (ndarray of shape (n, n_components)):\nTCAM projections in 2D transformed space.</li>\n</ul>\n\n<h6 id=\"notes\">Notes</h6>\n\n<p>The tensor m-product from Kilmer et al. (2021) has a notion of tensor\ninverse, and tensor orthogonality.</p>\n\n<p>We benchmarked an alternative approach as taken by sklearn in their\nPCA class. If we right multiply A's tSVDM by $V$ we note that it\ncancels the $V^T$ giving us:\n    $$\n        Z = A *_M V = U *_M S\n    $$\nIt appears that computing the final term is more computationally\nefficient, even if we have to convert $S$ into its full (sparse)\ntensor representation.</p>\n\n<p>By contrast, transform(X) will simply compute\n    $$\n        Z = A *_M V\n    $$</p>\n\n<p>In both cases, $Z$ still needs to be converted by $\\times_3 M^{-1}$\nand 'compressed' before being returned.\nFor these details see Mor et al. (2022).</p>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"param\"><span class=\"bp\">self</span>, </span><span class=\"param\"><span class=\"n\">X</span>, </span><span class=\"param\"><span class=\"n\">y</span><span class=\"o\">=</span><span class=\"kc\">None</span></span><span class=\"return-annotation\">):</span></span>", "funcdef": "def"}, {"fullname": "tred.display_tensor_facewise", "modulename": "tred", "qualname": "display_tensor_facewise", "kind": "function", "doc": "<p>Display an order-3 tensor represented by a Numpy ndarray nicely.</p>\n\n<p>By default Numpy prints order-3 arrays as vertical stacks of order-2\narrays in line with their broadcasting rules. This function prints a\ntranspose view so the print output is a more intuitive sequence of frontal\nslices. It also prints the rounded values.</p>\n\n<p>We often use this in notebooks.</p>\n\n<p>UPDATE (v0.1.1): Also works for matrices and vectors now.</p>\n\n<h6 id=\"parameters\">Parameters</h6>\n\n<ul>\n<li><strong>tens</strong> (ndarray of shape (n, p, t)):\nOrder-3 tensor.</li>\n</ul>\n\n<h6 id=\"examples\">Examples</h6>\n\n<div class=\"pdoc-code codehilite\">\n<pre><span></span><code><span class=\"gp\">&gt;&gt;&gt; </span><span class=\"kn\">import</span> <span class=\"nn\">numpy</span> <span class=\"k\">as</span> <span class=\"nn\">np</span>\n<span class=\"gp\">&gt;&gt;&gt; </span><span class=\"kn\">from</span> <span class=\"nn\">tred</span> <span class=\"kn\">import</span> <span class=\"n\">display_tensor_facewise</span> <span class=\"k\">as</span> <span class=\"n\">disp</span>\n<span class=\"gp\">&gt;&gt;&gt; </span><span class=\"n\">test</span> <span class=\"o\">=</span> <span class=\"n\">np</span><span class=\"o\">.</span><span class=\"n\">eye</span><span class=\"p\">(</span><span class=\"mi\">3</span><span class=\"p\">)[:,</span> <span class=\"p\">:,</span> <span class=\"kc\">None</span><span class=\"p\">]</span> <span class=\"c1\"># a 3x3x1 tensor</span>\n<span class=\"gp\">&gt;&gt;&gt; </span><span class=\"nb\">print</span><span class=\"p\">(</span><span class=\"n\">test</span><span class=\"p\">)</span> <span class=\"c1\"># Numpy ndarrays default __str__ method is not intuitive</span>\n<span class=\"go\">[[[1.]</span>\n<span class=\"go\">[0.]</span>\n<span class=\"go\">[0.]]</span>\n<span class=\"go\">[[0.]</span>\n<span class=\"go\">[1.]</span>\n<span class=\"go\">[0.]]</span>\n<span class=\"go\">[[0.]</span>\n<span class=\"go\">[0.]</span>\n<span class=\"go\">[1.]]]</span>\n<span class=\"gp\">&gt;&gt;&gt; </span><span class=\"n\">disp</span><span class=\"p\">(</span><span class=\"n\">test</span><span class=\"p\">)</span>\n<span class=\"go\">Tensor with dimensions (3, 3, 1)</span>\n<span class=\"go\">[[[1. 0. 0.]</span>\n<span class=\"go\">[0. 1. 0.]</span>\n<span class=\"go\">[0. 0. 1.]]]</span>\n</code></pre>\n</div>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"param\"><span class=\"n\">tens</span></span><span class=\"return-annotation\">):</span></span>", "funcdef": "def"}, {"fullname": "tred.generate_default_m_transform_pair", "modulename": "tred", "qualname": "generate_default_m_transform_pair", "kind": "function", "doc": "<p>Return the default <code>M, Minv</code> used by <code>tred</code> algorithms.</p>\n\n<p>We do not guarantee that the default m-transform used in <code>tred</code> will remain\nconsistent between versions, as this may change depending on recent\nresearch and literature. We highly encourage <code>tred</code> users to explicitly\ndefine M and Minv in the calling state to 'future-proof' your code.</p>\n\n<h6 id=\"parameters\">Parameters</h6>\n\n<ul>\n<li><strong>t</strong> (int):\nThe length of the tubal fibers of the target tensors, i.e. the size of\nits third dimension.</li>\n</ul>\n\n<h6 id=\"returns\">Returns</h6>\n\n<ul>\n<li><strong>M</strong> (Callable[[ndarray], ndarray]):\nA function which expects an order-3 tensor as input, and returns the\nimage under the default m-transform being used in <code>tred</code></li>\n<li><strong>Minv</strong> (Callable[[ndarray], ndarray]):\nA function implementing the inverse transform of <code>M</code>.</li>\n</ul>\n\n<h6 id=\"references\">References</h6>\n\n<p>Kilmer, M.E., Horesh, L., Avron, H. and Newman, E., 2021. Tensor-tensor\nalgebra for optimal representation and compression of multiway data.\nProceedings of the National Academy of Sciences, 118(28), p.e2015851118.</p>\n\n<p>Mor, U., Cohen, Y., Vald\u00e9s-Mas, R., Kviatcovsky, D., Elinav, E. and Avron,\nH., 2022. Dimensionality reduction of longitudinal\u2019omics data using modern\ntensor factorizations. PLoS Computational Biology, 18(7), p.e1010212.</p>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"param\"><span class=\"n\">t</span></span><span class=\"return-annotation\">):</span></span>", "funcdef": "def"}, {"fullname": "tred.generate_transform_pair_from_matrix", "modulename": "tred", "qualname": "generate_transform_pair_from_matrix", "kind": "function", "doc": "<p>Return <code>M, Minv</code> as defined by an orthogonal matrix.</p>\n\n<p>Allows the user to specify any orthogonal matrix, and this function will\ninfer <code>t</code>, and numerically compute the inverse, returning functions <code>M</code>\nand <code>Minv</code> which can be used for <code>tred</code> algorithms.</p>\n\n<p>Optionally, the user can also choose to specify the inverse explicitly.</p>\n\n<h6 id=\"parameters\">Parameters</h6>\n\n<ul>\n<li><strong>M_mat</strong> (ndarray):\nOrthogonal square matrix.</li>\n<li><strong>Minv_mat</strong> (ndarray or None, default=None):\nSquare matrix, the inverse of M_mat. If not specified, this function\nwill numerically evaluate the inverse of <code>M_mat</code>.</li>\n<li><strong>inplace</strong> (bool, default=False):\n<em>Placeholder for future development</em></li>\n</ul>\n\n<h6 id=\"returns\">Returns</h6>\n\n<ul>\n<li><strong>M</strong> (Callable[[ndarray], ndarray]):\nA function which expects an order-3 tensor as input, and applies\n<code>M_mat</code> to each of the tubal fibres. This preserves the dimensions of\nthe tensor.</li>\n<li><strong>Minv</strong> (Callable[[ndarray], ndarray]):\nA function implementing the inverse transform of <code>M</code>.</li>\n</ul>\n\n<h6 id=\"references\">References</h6>\n\n<p>Kilmer, M.E., Horesh, L., Avron, H. and Newman, E., 2021. Tensor-tensor\nalgebra for optimal representation and compression of multiway data.\nProceedings of the National Academy of Sciences, 118(28), p.e2015851118.</p>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"param\"><span class=\"n\">M_mat</span>, </span><span class=\"param\"><span class=\"n\">Minv_mat</span><span class=\"o\">=</span><span class=\"kc\">None</span>, </span><span class=\"param\"><span class=\"o\">*</span>, </span><span class=\"param\"><span class=\"n\">inplace</span><span class=\"o\">=</span><span class=\"kc\">False</span></span><span class=\"return-annotation\">):</span></span>", "funcdef": "def"}, {"fullname": "tred.generate_dctii_m_transform_pair", "modulename": "tred", "qualname": "generate_dctii_m_transform_pair", "kind": "function", "doc": "<p>Return <code>M, Minv</code> as defined by the Discrete Cosine Transform of\nlength <code>t</code>.</p>\n\n<p>Bascially a wrapper around scipy.fft to generate functions to perform\nfourier transform based $\\times_3 M$ operations, as used by\nMor et al. (2022)</p>\n\n<h6 id=\"parameters\">Parameters</h6>\n\n<ul>\n<li><strong>t</strong> (int):\nThe length of the transform</li>\n<li><strong>inplace</strong> (bool, default=False):\nControl whether or not the generated functions modify the input tensor\nin-place, or return a copy with the m-transform applied</li>\n<li><strong>norm</strong> ({\u201cbackward\u201d, \u201cortho\u201d, \u201cforward\u201d}, default=\"ortho\"):\nSee <a href=\"https://docs.scipy.org/doc/scipy/reference/generated/scipy.fft.dct.html#scipy.fft.dct\">https://docs.scipy.org/doc/scipy/reference/generated/scipy.fft.dct.html#scipy.fft.dct</a></li>\n</ul>\n\n<h6 id=\"returns\">Returns</h6>\n\n<ul>\n<li><strong>M</strong> (Callable[[ndarray], ndarray]):\nA function which expects an order-3 tensor as input, and applies the\nDCT-II transorm to each of the tubal fibres. This preserves the\ndimensions of the tensor.</li>\n<li><strong>Minv</strong> (Callable[[ndarray], ndarray]):\nA function implementing the inverse transform of <code>M</code>.</li>\n</ul>\n\n<h6 id=\"references\">References</h6>\n\n<p>Mor, U., Cohen, Y., Vald\u00e9s-Mas, R., Kviatcovsky, D., Elinav, E. and Avron,\nH., 2022. Dimensionality reduction of longitudinal\u2019omics data using modern\ntensor factorizations. PLoS Computational Biology, 18(7), p.e1010212.</p>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"param\"><span class=\"n\">t</span>, </span><span class=\"param\"><span class=\"o\">*</span>, </span><span class=\"param\"><span class=\"n\">inplace</span><span class=\"o\">=</span><span class=\"kc\">False</span>, </span><span class=\"param\"><span class=\"n\">norm</span><span class=\"o\">=</span><span class=\"s1\">&#39;ortho&#39;</span></span><span class=\"return-annotation\">):</span></span>", "funcdef": "def"}, {"fullname": "tred.generate_dstii_m_transform_pair", "modulename": "tred", "qualname": "generate_dstii_m_transform_pair", "kind": "function", "doc": "<p>Return <code>M, Minv</code> as defined by the Discrete Sine Transform of\nlength <code>t</code>.</p>\n\n<p>Bascially a wrapper around scipy.fft to generate functions to perform\nfourier transform based $\\times_3 M$ operations.</p>\n\n<h6 id=\"parameters\">Parameters</h6>\n\n<ul>\n<li><strong>t</strong> (int):\nThe length of the transform</li>\n<li><strong>inplace</strong> (bool, default=False):\nControl whether or not the generated functions modify the input tensor\nin-place, or return a copy with the m-transform applied</li>\n<li><strong>norm</strong> ({\u201cbackward\u201d, \u201cortho\u201d, \u201cforward\u201d}, default=\"ortho\"):\nSee <a href=\"https://docs.scipy.org/doc/scipy/reference/generated/scipy.fft.dst.html#scipy.fft.dst\">https://docs.scipy.org/doc/scipy/reference/generated/scipy.fft.dst.html#scipy.fft.dst</a></li>\n</ul>\n\n<h6 id=\"returns\">Returns</h6>\n\n<ul>\n<li><strong>M</strong> (Callable[[ndarray], ndarray]):\nA function which expects an order-3 tensor as input, and applies the\nDST-II transorm to each of the tubal fibres. This preserves the\ndimensions of the tensor.</li>\n<li><strong>Minv</strong> (Callable[[ndarray], ndarray]):\nA function implementing the inverse transform of <code>M</code>.</li>\n</ul>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"param\"><span class=\"n\">t</span>, </span><span class=\"param\"><span class=\"o\">*</span>, </span><span class=\"param\"><span class=\"n\">inplace</span><span class=\"o\">=</span><span class=\"kc\">False</span>, </span><span class=\"param\"><span class=\"n\">norm</span><span class=\"o\">=</span><span class=\"s1\">&#39;ortho&#39;</span></span><span class=\"return-annotation\">):</span></span>", "funcdef": "def"}, {"fullname": "tred.facewise_product", "modulename": "tred", "qualname": "facewise_product", "kind": "function", "doc": "<p>Compute cumulative facewise product.</p>\n\n<p>Definition:\n$$\n    C_{:,:,i} = A_{:,:,i} B_{:,:,i}\n$$</p>\n\n<h6 id=\"parameters\">Parameters</h6>\n\n<ul>\n<li><strong>*tensors</strong> (ndarray):\nVariable number of tensors, such that all adjacent input tensors have\nshape (a, b, d) and shape (b, c, d) respectively</li>\n</ul>\n\n<h6 id=\"returns\">Returns</h6>\n\n<ul>\n<li><strong>C</strong> (ndarray of shape (a, c, d)):\nFacewise tensor product</li>\n</ul>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"param\"><span class=\"o\">*</span><span class=\"n\">tensors</span></span><span class=\"return-annotation\">):</span></span>", "funcdef": "def"}, {"fullname": "tred.m_product", "modulename": "tred", "qualname": "m_product", "kind": "function", "doc": "<p>Kilmer et al. (2021) tensor m-product for order-3 tensors.</p>\n\n<p>See paper for definition.</p>\n\n<h6 id=\"parameters\">Parameters</h6>\n\n<ul>\n<li><strong>*tensors</strong> (ndarray):\nVariable number of tensors, such that all adjacent input tensors have\nshape (a, b, d) and shape (b, c, d) respectively</li>\n<li><strong>M</strong> (Callable[[ndarray], ndarray] or None, default=None):\nA function which, given some order-3 tensor, returns it under an\northogonal tubal transformation</li>\n<li><strong>MInv</strong> (Callable[[ndarray], ndarray] or None, default=None):\nA function implementing the inverse tubal transformation of M</li>\n</ul>\n\n<h6 id=\"returns\">Returns</h6>\n\n<ul>\n<li><strong>m_product</strong> (ndarray of shape (a, c, d)):\nTensor-tensor m-product as found in Kilmer et al. (2021)</li>\n</ul>\n\n<h6 id=\"references\">References</h6>\n\n<p>Kilmer, M.E., Horesh, L., Avron, H. and Newman, E., 2021. Tensor-tensor\nalgebra for optimal representation and compression of multiway data.\nProceedings of the National Academy of Sciences, 118(28), p.e2015851118.</p>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"param\"><span class=\"o\">*</span><span class=\"n\">tensors</span>, </span><span class=\"param\"><span class=\"o\">**</span><span class=\"n\">transforms</span></span><span class=\"return-annotation\">):</span></span>", "funcdef": "def"}, {"fullname": "tred.datasets", "modulename": "tred.datasets", "kind": "module", "doc": "<p></p>\n"}];

    // mirrored in build-search-index.js (part 1)
    // Also split on html tags. this is a cheap heuristic, but good enough.
    elasticlunr.tokenizer.setSeperator(/[\s\-.;&_'"=,()]+|<[^>]*>/);

    let searchIndex;
    if (docs._isPrebuiltIndex) {
        console.info("using precompiled search index");
        searchIndex = elasticlunr.Index.load(docs);
    } else {
        console.time("building search index");
        // mirrored in build-search-index.js (part 2)
        searchIndex = elasticlunr(function () {
            this.pipeline.remove(elasticlunr.stemmer);
            this.pipeline.remove(elasticlunr.stopWordFilter);
            this.addField("qualname");
            this.addField("fullname");
            this.addField("annotation");
            this.addField("default_value");
            this.addField("signature");
            this.addField("bases");
            this.addField("doc");
            this.setRef("fullname");
        });
        for (let doc of docs) {
            searchIndex.addDoc(doc);
        }
        console.timeEnd("building search index");
    }

    return (term) => searchIndex.search(term, {
        fields: {
            qualname: {boost: 4},
            fullname: {boost: 2},
            annotation: {boost: 2},
            default_value: {boost: 2},
            signature: {boost: 2},
            bases: {boost: 2},
            doc: {boost: 1},
        },
        expand: true
    });
})();